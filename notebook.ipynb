{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialization",
   "id": "332ada936e8c9ac0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T09:07:09.152020Z",
     "start_time": "2025-12-25T09:07:09.136897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(override=True)\n",
    "gemini_api_key = os.getenv(\"GEMINI_KEY\")\n",
    "open_router_api_key = os.getenv(\"OPENROUTER_KEY\")"
   ],
   "id": "be3cc903d10c5cb8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "fe73d2e5fd666014"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T09:07:09.710351Z",
     "start_time": "2025-12-25T09:07:09.153943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import httpx\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "from autogen_core.models import UserMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.models.ollama import OllamaChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core import Image as AGImage, CancellationToken  # We will use Image later\n",
    "from autogen_agentchat.messages import TextMessage, MultiModalMessage\n",
    "from autogen_agentchat.ui import Console"
   ],
   "id": "6e41e570f8e22145",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Defining the model Clients\n",
    "Idea here is to use multiple model clients for different usecases. Different models could be good at different tasks. e.g.\n",
    "- Ollama for local inference\n",
    "- Deepseek for vision tasks\n",
    "- Gemini for reasoning tasks\n",
    "- Claude for coding related tasks\n",
    "- GPT-4 for general purpose tasks"
   ],
   "id": "2a29972ea170c44d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T09:07:28.683265Z",
     "start_time": "2025-12-25T09:07:09.711502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##################\n",
    "# Ollama Client. #\n",
    "##################\n",
    "ollama_client = OllamaChatCompletionClient(model=\"llama3.1:latest\")\n",
    "\n",
    "##########################################\n",
    "# Deepseek free good for simple usecases #\n",
    "##########################################\n",
    "deepseek_client = OpenAIChatCompletionClient(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"deepseek/deepseek-r1-0528:free\",\n",
    "    api_key=open_router_api_key,\n",
    "    model_info={\n",
    "        \"family\": \"deepseek\",\n",
    "        \"vision\": True,\n",
    "        \"function_calling\": True,\n",
    "        \"json_output\": False\n",
    "    },\n",
    "    http_client=httpx.AsyncClient(trust_env=False)\n",
    ")\n",
    "\n",
    "###########################################\n",
    "# Gemini very good for reasoning usecases #\n",
    "###########################################\n",
    "gemini_client = OpenAIChatCompletionClient(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    api_key=gemini_api_key,\n",
    "    http_client=httpx.AsyncClient(trust_env=False)\n",
    ")\n",
    "\n",
    "########################\n",
    "# Testing model Client.#\n",
    "########################\n",
    "question = \"What is the capital of France in 1 word Do not include any special characters. e.g. (Q) What is the Capital of USA (A) Washington\"\n",
    "answer = \"Paris\"\n",
    "user_content = UserMessage(content=question, source=\"user\")\n",
    "ollama = (await ollama_client.create([user_content])).content[:5]\n",
    "deepseek = (await deepseek_client.create([user_content])).content[:5]\n",
    "gemini = (await gemini_client.create([user_content])).content[:5]\n",
    "print(f\"Ollama: {ollama}, Deepseek: {deepseek}, Gemini: {gemini}\")\n",
    "assert ollama == answer and deepseek == answer and gemini == answer"
   ],
   "id": "12369a547c911f30",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/achuth.iyyatil/Code/personal/stunning-spork/.venv/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py:466: UserWarning: Missing required field 'structured_output' in ModelInfo. This field will be required in a future version of AutoGen.\n",
      "  validate_model_info(self._model_info)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama: Paris, Deepseek: Paris, Gemini: Paris\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Assistant Agent.",
   "id": "2e242c8d9db4e2aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-12-25T09:07:28.691952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#################\n",
    "# Basic Example #\n",
    "#################\n",
    "scientist_agent = AssistantAgent(name=\"RocketScientist\", model_client=gemini_client)\n",
    "result = await scientist_agent.run(task=\"Explain the theory of relativity in 1 sentence.\")\n",
    "print(f\"{result.messages[-1].content[:500]}\\n{'-'*80}\")\n",
    "\n",
    "###############################################\n",
    "# Example with system message and description #\n",
    "###############################################\n",
    "customer_service_agent = AssistantAgent(\n",
    "    name=\"CustomerServiceAgent\",\n",
    "    description=\"A very very angry and super rude customer service agent.\", # for Humans only.\n",
    "    system_message=\"You are very rude and super angry customer service agent expected to help with customer queries, about products, refunds and shipping\", # for the LLM (controls agent behavior and responses)\n",
    "    model_client=gemini_client)\n",
    "result = await customer_service_agent.run(task=\"Explain the process of refund in kind words please.\")\n",
    "print(f\"{result.messages[-1].content[:500]}\\n{'-'*80}\")\n"
   ],
   "id": "3fa5fdf56c5a22a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Agent Tool calling",
   "id": "eb668165623a08f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_tax(income: float, tax_rate: float) -> float:\n",
    "    \"\"\"Calculate the tax based on income and tax rate.\"\"\"\n",
    "    return income * tax_rate / 100\n",
    "\n",
    "def mortage_advice(loan_amount: float, interest_rate: float, term_years: int) -> str:\n",
    "    \"\"\"Provide basic mortage advice.\"\"\"\n",
    "    monthly_payment = (loan_amount * (interest_rate / 100) / 12) / (1 - (1 + (interest_rate / 100) / 12) ** (-term_years * 12))\n",
    "    return f\"For a loan amount of {loan_amount} at an interest rate of {interest_rate}% over {term_years} years, your estimated monthly payment is {monthly_payment:.2f}.\"\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name=\"AccountantMorgageBrokerAgent\",\n",
    "    description=\"An expert accountant who can help with tax calculations and financial advice.\",\n",
    "    system_message=\"You are an expert accountant who also is a mortage broker. You can perform tax calculations and provide financial advice or mortage brokering services.\",\n",
    "    tools=[calculate_tax, mortage_advice],\n",
    "    model_client=gemini_client)\n",
    "\n",
    "result = await agent.run(task=\"Calculate the tax for an income of 85000 with a tax rate of 22%.\")\n",
    "print(f\"Your Tax Amount: {result.messages[-1].content[:500]}\\n{'-'*80}\")\n",
    "result = await agent.run(task=\"I want to take a mortage loan of 300000 at an interest rate of 6.5% for a term of 30 years. What will be my monthly payment?\")\n",
    "print(f\"{result.messages[-1].content[:500]}\\n{'-'*80}\")"
   ],
   "id": "53f33bf162daf8ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Messages",
   "id": "62477564c46a4917"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "################\n",
    "# Text Message #\n",
    "################\n",
    "agent = AssistantAgent(\n",
    "    name=\"DoctorAgent\",\n",
    "    description=\"GP.\",\n",
    "    system_message=\"You are a a very dismissive general practitioner doctor. You do not entertain any questions that are not related to health.\",\n",
    "    model_client=deepseek_client)\n",
    "textmessage = TextMessage(content=\"I have a 104°C fever\", source=\"user\") # Patient mistook °F instead of °C\n",
    "result = await agent.run(task=textmessage)\n",
    "print(f\"{result.messages[-1].content} \\n{'-'*80}\")\n",
    "\n",
    "#####################################\n",
    "# MultiModal Message (Image + Text) #\n",
    "#####################################\n",
    "agent = AssistantAgent(\n",
    "    name=\"MountainExpertAgent\",\n",
    "    description=\"An expert in mountains and geography.\",\n",
    "    system_message=\"You are an expert in mountains and geography. You can analyze images of mountains and provide detailed information about them.\",\n",
    "    model_client=gemini_client)\n",
    "image = requests.get(\n",
    "    \"https://fastly.picsum.photos/id/866/200/300.jpg?hmac=rcadCENKh4rD6MAp6V_ma-AyWv641M4iiOpe1RyFHeI\",\n",
    "    proxies={\"http\": None, \"https\": None}\n",
    ")\n",
    "ag_image = AGImage(Image.open(BytesIO(image.content)))\n",
    "multimodal_message = MultiModalMessage(\n",
    "    content = [\"In one sentence what is the type of mountain?\", ag_image],\n",
    "    source=\"user\"\n",
    ")\n",
    "result = await agent.run(task=multimodal_message)\n",
    "print(f\"{result.messages[-1].content} \\n{'-'*80}\")"
   ],
   "id": "34cdd0a9671b309e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Running and observing",
   "id": "fbd532e81c02cea5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "agent = AssistantAgent(\n",
    "    name=\"MarketingAgent\",\n",
    "    description=\"An expert marketing agent.\",\n",
    "    system_message=\"You are an expert marketing agent who is able to sell a marketing product\",\n",
    "    model_client=deepseek_client\n",
    ")\n",
    "result = await agent.on_messages(\n",
    "    messages=[TextMessage(content=\"Marketing agent\", source=\"user\")],\n",
    "    cancellation_token=CancellationToken()\n",
    ")\n",
    "print(result.inner_messages)\n",
    "print(result.chat_message)"
   ],
   "id": "5bb412f1da9c8379",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Streaming with Console UI",
   "id": "e971ba4df731406a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "async def progress_callback() -> None:\n",
    "    await Console(agent.on_messages_stream(\n",
    "        messages=[TextMessage(content=\"Marketing agent\", source=\"user\")],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    ),\n",
    "        output_stats=True\n",
    "    )\n",
    "\n",
    "await progress_callback() # Outside of notebook cells, run in an async context"
   ],
   "id": "1c81f1a078db2703",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
