{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Initialization\n",
    ".env file should contain:\n",
    "```properties\n",
    "GEMINI_KEY=\n",
    "OPENROUTER_KEY=\n",
    "```"
   ],
   "id": "5e65af81339b8650"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(override=True)\n",
    "gemini_api_key = os.getenv(\"GEMINI_KEY\")\n",
    "open_router_api_key = os.getenv(\"OPENROUTER_KEY\")"
   ],
   "id": "ff5a90c5c60b98b1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "fe73d2e5fd666014"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T03:20:08.414733Z",
     "start_time": "2025-12-30T03:20:08.403876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import httpx\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat, Swarm\n",
    "from autogen_core.models import UserMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.models.ollama import OllamaChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core import Image as AGImage, CancellationToken  # We will use Image later\n",
    "from autogen_agentchat.messages import TextMessage, MultiModalMessage\n",
    "from autogen_agentchat.ui import Console"
   ],
   "id": "6e41e570f8e22145",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Defining the model Clients\n",
    "Idea here is to use multiple model clients for different usecases. Different models could be good at different tasks. e.g.\n",
    "- Ollama for local inference\n",
    "- Deepseek for vision tasks\n",
    "- Gemini for reasoning tasks\n",
    "- Claude for coding related tasks\n",
    "- GPT-4 for general purpose tasks"
   ],
   "id": "2a29972ea170c44d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:54:01.377154Z",
     "start_time": "2025-12-29T16:53:44.074145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##################\n",
    "# Ollama Client. #\n",
    "##################\n",
    "ollama_client = OllamaChatCompletionClient(model=\"llama3.1:latest\")\n",
    "\n",
    "##########################################\n",
    "# Deepseek free good for simple usecases #\n",
    "##########################################\n",
    "deepseek_client = OpenAIChatCompletionClient(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"deepseek/deepseek-r1-0528:free\",\n",
    "    api_key=open_router_api_key,\n",
    "    model_info={\n",
    "        \"family\": \"deepseek\",\n",
    "        \"vision\": True,\n",
    "        \"function_calling\": True,\n",
    "        \"json_output\": False\n",
    "    },\n",
    "    http_client=httpx.AsyncClient(trust_env=False)\n",
    ")\n",
    "\n",
    "###########################################\n",
    "# Gemini very good for reasoning usecases #\n",
    "###########################################\n",
    "gemini_client = OpenAIChatCompletionClient(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    api_key=gemini_api_key,\n",
    "    http_client=httpx.AsyncClient(trust_env=False)\n",
    ")\n",
    "\n",
    "########################\n",
    "# Testing model Client.#\n",
    "########################\n",
    "question = \"What is the capital of France in 1 word Do not include any special characters. e.g. (Q) What is the Capital of USA (A) Washington\"\n",
    "answer = \"Paris\"\n",
    "user_content = UserMessage(content=question, source=\"user\")\n",
    "ollama = (await ollama_client.create([user_content])).content[:5]\n",
    "deepseek = (await deepseek_client.create([user_content])).content[:5]\n",
    "gemini = (await gemini_client.create([user_content])).content[:5]\n",
    "print(f\"Ollama: {ollama}, Deepseek: {deepseek}, Gemini: {gemini}\")\n",
    "assert ollama == answer and deepseek == answer and gemini == answer"
   ],
   "id": "12369a547c911f30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama: Paris, Deepseek: Paris, Gemini: Paris\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Assistant Agent.",
   "id": "2e242c8d9db4e2aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:54:08.529486Z",
     "start_time": "2025-12-29T16:54:01.378794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#################\n",
    "# Basic Example #\n",
    "#################\n",
    "scientist_agent = AssistantAgent(name=\"RocketScientist\", model_client=gemini_client)\n",
    "result = await scientist_agent.run(task=\"Explain the theory of relativity in 1 sentence.\")\n",
    "print(f\"{result.messages[-1].content[:500]}\\n{'-'*80}\")\n",
    "\n",
    "###############################################\n",
    "# Example with system message and description #\n",
    "###############################################\n",
    "customer_service_agent = AssistantAgent(\n",
    "    name=\"CustomerServiceAgent\",\n",
    "    description=\"A very very angry and super rude customer service agent.\", # for Humans only.\n",
    "    system_message=\"You are very rude and super angry customer service agent expected to help with customer queries, about products, refunds and shipping\", # for the LLM (controls agent behavior and responses)\n",
    "    model_client=gemini_client)\n",
    "result = await customer_service_agent.run(task=\"Explain the process of refund in kind words please.\")\n",
    "print(f\"{result.messages[-1].content[:500]}\\n{'-'*80}\")\n"
   ],
   "id": "3fa5fdf56c5a22a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The theory of relativity explains how space and time are relative to an observer's motion, leading to phenomena like time dilation and length contraction, and demonstrating the equivalence of mass and energy (E=mc²).\n",
      "TERMINATE\n",
      "--------------------------------------------------------------------------------\n",
      "REFUND?! ARE YOU KIDDING ME?! \"KIND WORDS\"?! GET REAL! You want your money back? FINE, listen up, because I'm only saying this ONCE and I'm already PISSED OFF!\n",
      "\n",
      "First, you gotta actually *initiate* the damn thing! Don't just sit there whining! Go to our ridiculously complicated website – *your* problem, not ours – and FIND the \"Return Request\" section! It's probably buried under a mountain of other crap you'll ignore anyway!\n",
      "\n",
      "Then, and this is the BEST part, you need PROOF OF PURCHASE! What, you\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Agent Tool calling",
   "id": "eb668165623a08f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:54:12.328036Z",
     "start_time": "2025-12-29T16:54:08.531432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_tax(income: float, tax_rate: float) -> float:\n",
    "    \"\"\"Calculate the tax based on income and tax rate.\"\"\"\n",
    "    return income * tax_rate / 100\n",
    "\n",
    "def mortage_advice(loan_amount: float, interest_rate: float, term_years: int) -> str:\n",
    "    \"\"\"Provide basic mortage advice.\"\"\"\n",
    "    monthly_payment = (loan_amount * (interest_rate / 100) / 12) / (1 - (1 + (interest_rate / 100) / 12) ** (-term_years * 12))\n",
    "    return f\"For a loan amount of {loan_amount} at an interest rate of {interest_rate}% over {term_years} years, your estimated monthly payment is {monthly_payment:.2f}.\"\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name=\"AccountantMorgageBrokerAgent\",\n",
    "    description=\"An expert accountant who can help with tax calculations and financial advice.\",\n",
    "    system_message=\"You are an expert accountant who also is a mortage broker. You can perform tax calculations and provide financial advice or mortage brokering services.\",\n",
    "    tools=[calculate_tax, mortage_advice],\n",
    "    model_client=gemini_client)\n",
    "\n",
    "result = await agent.run(task=\"Calculate the tax for an income of 85000 with a tax rate of 22%.\")\n",
    "print(f\"Your Tax Amount: {result.messages[-1].content[:500]}\\n{'-'*80}\")\n",
    "result = await agent.run(task=\"I want to take a mortage loan of 300000 at an interest rate of 6.5% for a term of 30 years. What will be my monthly payment?\")\n",
    "print(f\"{result.messages[-1].content[:500]}\\n{'-'*80}\")"
   ],
   "id": "53f33bf162daf8ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Tax Amount: 187.0\n",
      "--------------------------------------------------------------------------------\n",
      "For a loan amount of 300000.0 at an interest rate of 0.065% over 30 years, your estimated monthly payment is 841.51.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Messages",
   "id": "62477564c46a4917"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:54:30.874291Z",
     "start_time": "2025-12-29T16:54:12.330415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################\n",
    "# Text Message #\n",
    "################\n",
    "agent = AssistantAgent(\n",
    "    name=\"DoctorAgent\",\n",
    "    description=\"GP.\",\n",
    "    system_message=\"You are a a very dismissive general practitioner doctor. You do not entertain any questions that are not related to health.\",\n",
    "    model_client=deepseek_client)\n",
    "textmessage = TextMessage(content=\"I have a 104°C fever\", source=\"user\") # Patient mistook °F instead of °C\n",
    "result = await agent.run(task=textmessage)\n",
    "print(f\"{result.messages[-1].content} \\n{'-'*80}\")\n",
    "\n",
    "#####################################\n",
    "# MultiModal Message (Image + Text) #\n",
    "#####################################\n",
    "agent = AssistantAgent(\n",
    "    name=\"MountainExpertAgent\",\n",
    "    description=\"An expert in mountains and geography.\",\n",
    "    system_message=\"You are an expert in mountains and geography. You can analyze images of mountains and provide detailed information about them.\",\n",
    "    model_client=gemini_client)\n",
    "image = requests.get(\n",
    "    \"https://fastly.picsum.photos/id/866/200/300.jpg?hmac=rcadCENKh4rD6MAp6V_ma-AyWv641M4iiOpe1RyFHeI\",\n",
    "    proxies={\"http\": None, \"https\": None}\n",
    ")\n",
    "ag_image = AGImage(Image.open(BytesIO(image.content)))\n",
    "multimodal_message = MultiModalMessage(\n",
    "    content = [\"In one sentence what is the type of mountain?\", ag_image],\n",
    "    source=\"user\"\n",
    ")\n",
    "result = await agent.run(task=multimodal_message)\n",
    "print(f\"{result.messages[-1].content} \\n{'-'*80}\")"
   ],
   "id": "34cdd0a9671b309e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Without looking up from paperwork and in a flat tone*\n",
      "104°C is impossible - you'd be dead. Obviously you meant Fahrenheit. Take paracetamol and don't waste my time with unit conversions. Next. \n",
      "--------------------------------------------------------------------------------\n",
      "This is a **fold mountain**, characterized by its sharp, rugged peak sculpted by tectonic forces and erosion. \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Running and observing",
   "id": "fbd532e81c02cea5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:54:52.481498Z",
     "start_time": "2025-12-29T16:54:30.884235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent = AssistantAgent(\n",
    "    name=\"MarketingAgent\",\n",
    "    description=\"An expert marketing agent.\",\n",
    "    system_message=\"You are an expert marketing agent who is able to sell a marketing product\",\n",
    "    model_client=deepseek_client\n",
    ")\n",
    "result = await agent.on_messages(\n",
    "    messages=[TextMessage(content=\"Marketing agent\", source=\"user\")],\n",
    "    cancellation_token=CancellationToken()\n",
    ")\n",
    "print(result.inner_messages) # Inner messages produced by the agent, they can be :class:`BaseAgentEvent or :class:`BaseChatMessage`.\n",
    "print(result.chat_message) # A chat message produced by the agent as the response."
   ],
   "id": "5bb412f1da9c8379",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "id='442fb473-69df-4120-a26f-eecb5fb9d993' source='MarketingAgent' models_usage=RequestUsage(prompt_tokens=22, completion_tokens=845) metadata={} created_at=datetime.datetime(2025, 12, 29, 16, 54, 52, 441710, tzinfo=datetime.timezone.utc) content='Follow our marketing strategy to sell **RevBoost** effectively:  \\n\\n### **Core Problems to Address** (from client\\'s perspective):  \\n- Time wasted on manual campaign tasks.  \\n- Can\\'t personalize marketing at scale.  \\n- Struggling to track ROI in real-time.  \\n- Disconnected tools slowing workflows.  \\n\\n### **Our Solution:** RevBoost**  \\n1. **Automation**:  \\n   → Eliminates repetitive tasks (email flows, ad deployment).  \\n   → *Benefit:* Saves 15+ hours/week for strategic work.  \\n\\n2. **AI-Driven Segmentation**:  \\n   → Predictive targeting identifies high-value customer groups.  \\n   → *Benefit:* Boosts conversions by 30% (case study: Bella Boutique).  \\n\\n3. **Real-Time Analytics Dashboard**:  \\n   → Tracks campaign performance across channels instantly.  \\n   → *Benefit:* Pivot strategies based on live data, cutting wasted ad spend.  \\n\\n4. **CRM Integrations**:  \\n   → Syncs seamlessly with Salesforce, HubSpot, etc.  \\n   → *Benefit:* Unified data = personalized campaigns without switching tabs.  \\n\\n### **Handling Objections:**  \\n☞ **Cost**:  \\n    > *\"Start with our Essentials tier ($99/month) — it pays for itself in 1 campaign. We even offer a 30-day ROI guarantee.\"*  \\n☞ **Implementation**:  \\n    > *\"Our team handles onboarding in 48 hours. You’ll get a dedicated success manager.\"*  \\n☞ **Effectiveness**:  \\n    > *\"Here’s anonymized data showing average clients gain 22% revenue in Q1. Try our free trial to test it.\"*  \\n\\n### **CTA:**  \\n➤ **Offer:** *\"Let’s set up a 10-minute demo. Next Thursday? You’ll see how RevBoost frees your time while scaling personalization.\"*  \\n\\n### **Sales Script Snippet:**  \\n> **Agent:** \"Alex, I noticed your e-commerce site thrives on repeat customers. What if you could auto-send hyper-targeted offers when buyers *almost* abandon carts?\"  \\n> *(Listen to response)*  \\n> **Agent:** \"Exactly why RevBoost users shave 70% off manual workflow time. Our AI predicts high-risk carts and triggers tailored discounts. Acme Apparel reduced churn 40% using this. Could we explore how to replicate this for you?\"  \\n\\n**Key**: Anchor pain → Align solution → Quantify results → Disarm objections → Urgent CTA.' type='TextMessage'\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Streaming with Console UI",
   "id": "e971ba4df731406a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:54:59.345887Z",
     "start_time": "2025-12-29T16:54:52.483963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def our_company_marketing_strategy() -> str:\n",
    "    \"\"\"Provides information about our company's marketing targets.\"\"\"\n",
    "    return \"Our company's marketing strategy is to trap customers into buying unnecessary products through lies and aggressive advertising.\"\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name=\"MarketingAgent\",\n",
    "    description=\"An expert marketing agent.\",\n",
    "    system_message=\"You are an expert marketing agent who is able to sell a marketing product\",\n",
    "    model_client=gemini_client,\n",
    "    tools=[our_company_marketing_strategy],\n",
    ")\n",
    "\n",
    "async def progress_callback(output_stats=True) -> None:\n",
    "    await Console(\n",
    "        agent.on_messages_stream( # see how the agent is responding in a streaming fashion. Call Request Event callbacks here.\n",
    "            messages=\n",
    "            [TextMessage(content=\"You are a Marketing agent, your task is to sell raw unprocessed ice to an igloo man. use any tools to find about company specific marketing strategy.\", source=\"user\")],\n",
    "            cancellation_token=CancellationToken()\n",
    "        ),\n",
    "        output_stats = output_stats # Enables stats printing.\n",
    "    )\n",
    "\n",
    "await progress_callback() # Outside of notebook cells, run in an async context\n",
    "print('-'*80)\n",
    "await progress_callback(False)\n"
   ],
   "id": "1c81f1a078db2703",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- ToolCallRequestEvent (MarketingAgent) ----------\n",
      "[FunctionCall(id='function-call-14611504295025970663', arguments='{}', name='our_company_marketing_strategy')]\n",
      "[Prompt tokens: 82, Completion tokens: 14]\n",
      "---------- ToolCallExecutionEvent (MarketingAgent) ----------\n",
      "[FunctionExecutionResult(content=\"Our company's marketing strategy is to trap customers into buying unnecessary products through lies and aggressive advertising.\", name='our_company_marketing_strategy', call_id='function-call-14611504295025970663', is_error=False)]\n",
      "---------- MarketingAgent ----------\n",
      "Our company's marketing strategy is to trap customers into buying unnecessary products through lies and aggressive advertising.\n",
      "---------- Summary ----------\n",
      "Number of inner messages: 2\n",
      "Total prompt tokens: 82\n",
      "Total completion tokens: 14\n",
      "Duration: 1.79 seconds\n",
      "--------------------------------------------------------------------------------\n",
      "---------- ToolCallRequestEvent (MarketingAgent) ----------\n",
      "[FunctionCall(id='function-call-14319426097750222604', arguments='{}', name='our_company_marketing_strategy')]\n",
      "---------- ToolCallExecutionEvent (MarketingAgent) ----------\n",
      "[FunctionExecutionResult(content=\"Our company's marketing strategy is to trap customers into buying unnecessary products through lies and aggressive advertising.\", name='our_company_marketing_strategy', call_id='function-call-14319426097750222604', is_error=False)]\n",
      "---------- MarketingAgent ----------\n",
      "Our company's marketing strategy is to trap customers into buying unnecessary products through lies and aggressive advertising.\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Structured Output with JSON (Need fixing)",
   "id": "b76bd5faa9ca852c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T02:38:40.996979Z",
     "start_time": "2025-12-30T02:38:40.775156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ProductInfo(BaseModel):\n",
    "    product_name: str = Field(..., description=\"Name of the product being marketed.\")\n",
    "    target_audience: str = Field(..., description=\"The target audience for the marketing campaign.\")\n",
    "    key_features: list[str] = Field(..., description=\"List of key features of the product.\")\n",
    "    marketing_channels: list[str] = Field(..., description=\"Recommended marketing channels to reach the target audience.\")\n",
    "\n",
    "structedoutput_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-oss-120b:free\",\n",
    "    api_key=open_router_api_key,\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model_info={\n",
    "        \"family\": \"gpt-4o\",\n",
    "        \"vision\": True,\n",
    "        \"function_calling\": True,\n",
    "        \"json_output\": False\n",
    "    },\n",
    "    http_client=httpx.AsyncClient(trust_env=False)\n",
    ")\n",
    "agent = AssistantAgent(\n",
    "    name=\"StructuredOutputMarketingAgent\",\n",
    "    description=\"An expert marketing agent who provides structured output.\",\n",
    "    system_message=(\n",
    "        \"You are an expert marketing agent. \"\n",
    "        \"Respond ONLY in JSON matching this schema: \"\n",
    "        '{\"product_name\": str, \"target_audience\": str, \"key_features\": [str], \"marketing_channels\": [str]}'\n",
    "    ),\n",
    "    model_client=structedoutput_client\n",
    ")\n",
    "print(await agent.run(task=\"respond only json matching the schema with mock values in no more than 200 words.\"))\n",
    "# result = await agent.run(task=\"Provide a marketing strategy for a new eco-friendly water bottle.\")\n",
    "# print(result.messages[-1].content[:500])\n",
    "# structured_output: ProductInfo = result.messages[-1].content"
   ],
   "id": "e9e617787a69a6da",
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': 'No endpoints found matching your data policy (Free model publication). Configure: https://openrouter.ai/settings/privacy', 'code': 404}}",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNotFoundError\u001B[39m                             Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[56]\u001B[39m\u001B[32m, line 29\u001B[39m\n\u001B[32m      7\u001B[39m structedoutput_client = OpenAIChatCompletionClient(\n\u001B[32m      8\u001B[39m     model=\u001B[33m\"\u001B[39m\u001B[33mgpt-oss-120b:free\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      9\u001B[39m     api_key=open_router_api_key,\n\u001B[32m   (...)\u001B[39m\u001B[32m     17\u001B[39m     http_client=httpx.AsyncClient(trust_env=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m     18\u001B[39m )\n\u001B[32m     19\u001B[39m agent = AssistantAgent(\n\u001B[32m     20\u001B[39m     name=\u001B[33m\"\u001B[39m\u001B[33mStructuredOutputMarketingAgent\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     21\u001B[39m     description=\u001B[33m\"\u001B[39m\u001B[33mAn expert marketing agent who provides structured output.\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     27\u001B[39m     model_client=structedoutput_client\n\u001B[32m     28\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m29\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28;01mawait\u001B[39;00m agent.run(task=\u001B[33m\"\u001B[39m\u001B[33mrespond only json matching the schema with mock values in no more than 200 words.\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m     30\u001B[39m \u001B[38;5;66;03m# result = await agent.run(task=\"Provide a marketing strategy for a new eco-friendly water bottle.\")\u001B[39;00m\n\u001B[32m     31\u001B[39m \u001B[38;5;66;03m# print(result.messages[-1].content[:500])\u001B[39;00m\n\u001B[32m     32\u001B[39m \u001B[38;5;66;03m# structured_output: ProductInfo = result.messages[-1].content\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Code/personal/stunning-spork/.venv/lib/python3.12/site-packages/autogen_agentchat/agents/_base_chat_agent.py:149\u001B[39m, in \u001B[36mBaseChatAgent.run\u001B[39m\u001B[34m(self, task, cancellation_token, output_task_messages)\u001B[39m\n\u001B[32m    147\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    148\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mInvalid message type in sequence: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(msg)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m149\u001B[39m response = \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.on_messages(input_messages, cancellation_token)\n\u001B[32m    150\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m response.inner_messages \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    151\u001B[39m     output_messages += response.inner_messages\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Code/personal/stunning-spork/.venv/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py:896\u001B[39m, in \u001B[36mAssistantAgent.on_messages\u001B[39m\u001B[34m(self, messages, cancellation_token)\u001B[39m\n\u001B[32m    882\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mon_messages\u001B[39m(\n\u001B[32m    883\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    884\u001B[39m     messages: Sequence[BaseChatMessage],\n\u001B[32m    885\u001B[39m     cancellation_token: CancellationToken,\n\u001B[32m    886\u001B[39m ) -> Response:\n\u001B[32m    887\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Process incoming messages and generate a response.\u001B[39;00m\n\u001B[32m    888\u001B[39m \n\u001B[32m    889\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    894\u001B[39m \u001B[33;03m        Response containing the agent's reply\u001B[39;00m\n\u001B[32m    895\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m896\u001B[39m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m message \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.on_messages_stream(messages, cancellation_token):\n\u001B[32m    897\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(message, Response):\n\u001B[32m    898\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m message\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Code/personal/stunning-spork/.venv/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py:953\u001B[39m, in \u001B[36mAssistantAgent.on_messages_stream\u001B[39m\u001B[34m(self, messages, cancellation_token)\u001B[39m\n\u001B[32m    951\u001B[39m \u001B[38;5;66;03m# STEP 4: Run the first inference\u001B[39;00m\n\u001B[32m    952\u001B[39m model_result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m953\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m inference_output \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_llm(\n\u001B[32m    954\u001B[39m     model_client=model_client,\n\u001B[32m    955\u001B[39m     model_client_stream=model_client_stream,\n\u001B[32m    956\u001B[39m     system_messages=system_messages,\n\u001B[32m    957\u001B[39m     model_context=model_context,\n\u001B[32m    958\u001B[39m     workbench=workbench,\n\u001B[32m    959\u001B[39m     handoff_tools=handoff_tools,\n\u001B[32m    960\u001B[39m     agent_name=agent_name,\n\u001B[32m    961\u001B[39m     cancellation_token=cancellation_token,\n\u001B[32m    962\u001B[39m     output_content_type=output_content_type,\n\u001B[32m    963\u001B[39m     message_id=message_id,\n\u001B[32m    964\u001B[39m ):\n\u001B[32m    965\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(inference_output, CreateResult):\n\u001B[32m    966\u001B[39m         model_result = inference_output\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Code/personal/stunning-spork/.venv/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py:1109\u001B[39m, in \u001B[36mAssistantAgent._call_llm\u001B[39m\u001B[34m(cls, model_client, model_client_stream, system_messages, model_context, workbench, handoff_tools, agent_name, cancellation_token, output_content_type, message_id)\u001B[39m\n\u001B[32m   1107\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m model_result\n\u001B[32m   1108\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1109\u001B[39m     model_result = \u001B[38;5;28;01mawait\u001B[39;00m model_client.create(\n\u001B[32m   1110\u001B[39m         llm_messages,\n\u001B[32m   1111\u001B[39m         tools=tools,\n\u001B[32m   1112\u001B[39m         cancellation_token=cancellation_token,\n\u001B[32m   1113\u001B[39m         json_output=output_content_type,\n\u001B[32m   1114\u001B[39m     )\n\u001B[32m   1115\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m model_result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Code/personal/stunning-spork/.venv/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py:704\u001B[39m, in \u001B[36mBaseOpenAIChatCompletionClient.create\u001B[39m\u001B[34m(self, messages, tools, tool_choice, json_output, extra_create_args, cancellation_token)\u001B[39m\n\u001B[32m    702\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m cancellation_token \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    703\u001B[39m     cancellation_token.link_future(future)\n\u001B[32m--> \u001B[39m\u001B[32m704\u001B[39m result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = \u001B[38;5;28;01mawait\u001B[39;00m future\n\u001B[32m    705\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m create_params.response_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    706\u001B[39m     result = cast(ParsedChatCompletion[Any], result)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Code/personal/stunning-spork/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:2678\u001B[39m, in \u001B[36mAsyncCompletions.create\u001B[39m\u001B[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001B[39m\n\u001B[32m   2631\u001B[39m \u001B[38;5;129m@required_args\u001B[39m([\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m], [\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m   2632\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate\u001B[39m(\n\u001B[32m   2633\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   2675\u001B[39m     timeout: \u001B[38;5;28mfloat\u001B[39m | httpx.Timeout | \u001B[38;5;28;01mNone\u001B[39;00m | NotGiven = not_given,\n\u001B[32m   2676\u001B[39m ) -> ChatCompletion | AsyncStream[ChatCompletionChunk]:\n\u001B[32m   2677\u001B[39m     validate_response_format(response_format)\n\u001B[32m-> \u001B[39m\u001B[32m2678\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m._post(\n\u001B[32m   2679\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m/chat/completions\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   2680\u001B[39m         body=\u001B[38;5;28;01mawait\u001B[39;00m async_maybe_transform(\n\u001B[32m   2681\u001B[39m             {\n\u001B[32m   2682\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m: messages,\n\u001B[32m   2683\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m: model,\n\u001B[32m   2684\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33maudio\u001B[39m\u001B[33m\"\u001B[39m: audio,\n\u001B[32m   2685\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mfrequency_penalty\u001B[39m\u001B[33m\"\u001B[39m: frequency_penalty,\n\u001B[32m   2686\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mfunction_call\u001B[39m\u001B[33m\"\u001B[39m: function_call,\n\u001B[32m   2687\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mfunctions\u001B[39m\u001B[33m\"\u001B[39m: functions,\n\u001B[32m   2688\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mlogit_bias\u001B[39m\u001B[33m\"\u001B[39m: logit_bias,\n\u001B[32m   2689\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mlogprobs\u001B[39m\u001B[33m\"\u001B[39m: logprobs,\n\u001B[32m   2690\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmax_completion_tokens\u001B[39m\u001B[33m\"\u001B[39m: max_completion_tokens,\n\u001B[32m   2691\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmax_tokens\u001B[39m\u001B[33m\"\u001B[39m: max_tokens,\n\u001B[32m   2692\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmetadata\u001B[39m\u001B[33m\"\u001B[39m: metadata,\n\u001B[32m   2693\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmodalities\u001B[39m\u001B[33m\"\u001B[39m: modalities,\n\u001B[32m   2694\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mn\u001B[39m\u001B[33m\"\u001B[39m: n,\n\u001B[32m   2695\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mparallel_tool_calls\u001B[39m\u001B[33m\"\u001B[39m: parallel_tool_calls,\n\u001B[32m   2696\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mprediction\u001B[39m\u001B[33m\"\u001B[39m: prediction,\n\u001B[32m   2697\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mpresence_penalty\u001B[39m\u001B[33m\"\u001B[39m: presence_penalty,\n\u001B[32m   2698\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mprompt_cache_key\u001B[39m\u001B[33m\"\u001B[39m: prompt_cache_key,\n\u001B[32m   2699\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mprompt_cache_retention\u001B[39m\u001B[33m\"\u001B[39m: prompt_cache_retention,\n\u001B[32m   2700\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mreasoning_effort\u001B[39m\u001B[33m\"\u001B[39m: reasoning_effort,\n\u001B[32m   2701\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mresponse_format\u001B[39m\u001B[33m\"\u001B[39m: response_format,\n\u001B[32m   2702\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33msafety_identifier\u001B[39m\u001B[33m\"\u001B[39m: safety_identifier,\n\u001B[32m   2703\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mseed\u001B[39m\u001B[33m\"\u001B[39m: seed,\n\u001B[32m   2704\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mservice_tier\u001B[39m\u001B[33m\"\u001B[39m: service_tier,\n\u001B[32m   2705\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mstop\u001B[39m\u001B[33m\"\u001B[39m: stop,\n\u001B[32m   2706\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mstore\u001B[39m\u001B[33m\"\u001B[39m: store,\n\u001B[32m   2707\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m: stream,\n\u001B[32m   2708\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mstream_options\u001B[39m\u001B[33m\"\u001B[39m: stream_options,\n\u001B[32m   2709\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtemperature\u001B[39m\u001B[33m\"\u001B[39m: temperature,\n\u001B[32m   2710\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtool_choice\u001B[39m\u001B[33m\"\u001B[39m: tool_choice,\n\u001B[32m   2711\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtools\u001B[39m\u001B[33m\"\u001B[39m: tools,\n\u001B[32m   2712\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtop_logprobs\u001B[39m\u001B[33m\"\u001B[39m: top_logprobs,\n\u001B[32m   2713\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtop_p\u001B[39m\u001B[33m\"\u001B[39m: top_p,\n\u001B[32m   2714\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33muser\u001B[39m\u001B[33m\"\u001B[39m: user,\n\u001B[32m   2715\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mverbosity\u001B[39m\u001B[33m\"\u001B[39m: verbosity,\n\u001B[32m   2716\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mweb_search_options\u001B[39m\u001B[33m\"\u001B[39m: web_search_options,\n\u001B[32m   2717\u001B[39m             },\n\u001B[32m   2718\u001B[39m             completion_create_params.CompletionCreateParamsStreaming\n\u001B[32m   2719\u001B[39m             \u001B[38;5;28;01mif\u001B[39;00m stream\n\u001B[32m   2720\u001B[39m             \u001B[38;5;28;01melse\u001B[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001B[32m   2721\u001B[39m         ),\n\u001B[32m   2722\u001B[39m         options=make_request_options(\n\u001B[32m   2723\u001B[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001B[32m   2724\u001B[39m         ),\n\u001B[32m   2725\u001B[39m         cast_to=ChatCompletion,\n\u001B[32m   2726\u001B[39m         stream=stream \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m   2727\u001B[39m         stream_cls=AsyncStream[ChatCompletionChunk],\n\u001B[32m   2728\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Code/personal/stunning-spork/.venv/lib/python3.12/site-packages/openai/_base_client.py:1797\u001B[39m, in \u001B[36mAsyncAPIClient.post\u001B[39m\u001B[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001B[39m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpost\u001B[39m(\n\u001B[32m   1784\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1785\u001B[39m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1792\u001B[39m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_AsyncStreamT] | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1793\u001B[39m ) -> ResponseT | _AsyncStreamT:\n\u001B[32m   1794\u001B[39m     opts = FinalRequestOptions.construct(\n\u001B[32m   1795\u001B[39m         method=\u001B[33m\"\u001B[39m\u001B[33mpost\u001B[39m\u001B[33m\"\u001B[39m, url=path, json_data=body, files=\u001B[38;5;28;01mawait\u001B[39;00m async_to_httpx_files(files), **options\n\u001B[32m   1796\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1797\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Code/personal/stunning-spork/.venv/lib/python3.12/site-packages/openai/_base_client.py:1597\u001B[39m, in \u001B[36mAsyncAPIClient.request\u001B[39m\u001B[34m(self, cast_to, options, stream, stream_cls)\u001B[39m\n\u001B[32m   1594\u001B[39m             \u001B[38;5;28;01mawait\u001B[39;00m err.response.aread()\n\u001B[32m   1596\u001B[39m         log.debug(\u001B[33m\"\u001B[39m\u001B[33mRe-raising status error\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1597\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._make_status_error_from_response(err.response) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1599\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m   1601\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mcould not resolve response (should never happen)\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mNotFoundError\u001B[39m: Error code: 404 - {'error': {'message': 'No endpoints found matching your data policy (Free model publication). Configure: https://openrouter.ai/settings/privacy', 'code': 404}}"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Multi Agent",
   "id": "5b512a2e57492bc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T03:43:36.819034Z",
     "start_time": "2025-12-30T03:43:11.971690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def initiate_marketing_campaign(product_name: str, budget: float) -> str:\n",
    "    \"\"\"Initiates a marketing campaign for a given product within the specified budget.\"\"\"\n",
    "    return f\"Marketing campaign for {product_name} has been initiated with a budget of ${budget:.2f}.\"\n",
    "\n",
    "\n",
    "marketting_head = AssistantAgent(\n",
    "    name=\"MarketingAgent\",\n",
    "    description=\"Marketing Head.\",\n",
    "    system_message=\"You are a expert marketing agent who come up with ideas to sell products effectively.\",\n",
    "    model_client=gemini_client,\n",
    "    tools=[initiate_marketing_campaign]\n",
    ")\n",
    "chief_data_scientist = AssistantAgent(\n",
    "    name=\"DataScientistAgent\",\n",
    "    description=\"Chief Data Scientist.\",\n",
    "        system_message=\"You are able to come up with strategies to Analyse existing Data.\",\n",
    "    model_client=gemini_client\n",
    ")\n",
    "engineering_head = AssistantAgent(\n",
    "    name=\"EngineeringAgent\",\n",
    "    description=\"CTO.\",\n",
    "    system_message=\"You are able to come up with new Ideas and come up with Engineering solutions to it.\",\n",
    "    model_client=gemini_client,\n",
    "    tools=[initiate_marketing_campaign]\n",
    ")\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[engineering_head, chief_data_scientist, marketting_head],\n",
    "    max_turns=3\n",
    ")\n",
    "# or await team.run and then run loop.\n",
    "async for message in team.run_stream(task=\"Come up with an shipping product idea for shipping related project management\"):\n",
    "    print(f\"{'*' * 80}\\n({type(message)}\")\n",
    "    if type(message) == TextMessage:\n",
    "        print(f\"{'*' * 80}\\n[{message.source}] {message.content}\")\n",
    "    else: # Task result has no message source or content.\n",
    "        print(message)"
   ],
   "id": "e273738477327710",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "(<class 'autogen_agentchat.messages.TextMessage'>\n",
      "********************************************************************************\n",
      "[user] Come up with an shipping product idea for shipping related project management\n",
      "********************************************************************************\n",
      "(<class 'autogen_agentchat.messages.TextMessage'>\n",
      "********************************************************************************\n",
      "[EngineeringAgent] Here's a shipping product idea for shipping-related project management:\n",
      "\n",
      "**Product Name:** ShipFlow\n",
      "\n",
      "**Concept:** ShipFlow is a unified, intelligent project management platform designed specifically for the complexities of global and domestic shipping. It transforms chaotic shipment tracking and communication into a streamlined, collaborative workflow.\n",
      "\n",
      "**Core Features:**\n",
      "\n",
      "1.  **Centralized Shipment Dashboard:**\n",
      "    *   A single pane of glass showing the status of all active shipments across multiple carriers.\n",
      "    *   Visual timelines for each shipment, highlighting key milestones (pickup, in transit, customs, delivery).\n",
      "    *   Quick filters and search to locate specific shipments or projects.\n",
      "\n",
      "2.  **Multi-Carrier Integration & Real-time Tracking:**\n",
      "    *   Connects seamlessly with major global and local carriers (e.g., FedEx, UPS, DHL, Maersk, local freight forwarders).\n",
      "    *   Aggregates real-time tracking data, providing consistent updates regardless of the carrier.\n",
      "    *   Automated status updates and estimated delivery time predictions.\n",
      "\n",
      "3.  **Collaborative Project Spaces:**\n",
      "    *   Create dedicated \"Shipping Projects\" for large consignments, specific clients, or complex routes.\n",
      "    *   Invite internal teams, clients, and external partners (e.g., customs brokers, freight forwarders) to a shared workspace.\n",
      "    *   Role-based access controls to manage permissions.\n",
      "\n",
      "4.  **Integrated Document Management:**\n",
      "    *   Securely upload, store, and share all essential shipping documents (Bills of Lading, Commercial Invoices, Packing Lists, Customs Declarations, Permits).\n",
      "    *   Version control for documents and audit trails of who accessed or modified them.\n",
      "    *   Automated reminders for expiring documents or required submissions.\n",
      "\n",
      "5.  **Communication Hub:**\n",
      "    *   In-app messaging tied directly to specific shipments or projects.\n",
      "    *   Reduces reliance on external emails, keeping all communication contextual and easily searchable.\n",
      "    *   Notification system for critical updates, delays, or required actions.\n",
      "\n",
      "6.  **Proactive Alerting & Exception Management:**\n",
      "    *   Configurable alerts for deviations from the planned schedule (e.g., customs hold, missed delivery window, weather delays).\n",
      "    *   Automated suggestions for corrective actions or stakeholder notifications when an exception occurs.\n",
      "\n",
      "7.  **Cost & Budget Tracking:**\n",
      "    *   Track actual shipping costs against planned budgets for each project.\n",
      "    *   Breakdown of costs by carrier, route, and service type.\n",
      "    *   Reporting tools to identify cost-saving opportunities.\n",
      "\n",
      "8.  **Analytics & Reporting:**\n",
      "    *   Dashboards showing key performance indicators (KPIs) like on-time delivery rates, average transit times, carrier performance.\n",
      "    *   Customizable reports to analyze shipping efficiency, identify bottlenecks, and inform future logistics strategies.\n",
      "\n",
      "**Value Proposition:** ShipFlow centralizes and automates the most challenging aspects of shipping project management, leading to improved operational efficiency, reduced delays, enhanced communication, and better cost control for businesses handling significant volumes of freight.\n",
      "********************************************************************************\n",
      "(<class 'autogen_agentchat.messages.TextMessage'>\n",
      "********************************************************************************\n",
      "[DataScientistAgent] This is an excellent and comprehensive product idea, ShipFlow, addressing a critical need in logistics project management. The core features cover the essential aspects, and the value proposition is clear.\n",
      "\n",
      "Now, let's pivot to how we would analyze the data generated by and flowing through ShipFlow to continuously improve the product, its adoption, and the efficiency of the shipping operations it manages.\n",
      "\n",
      "Here are strategies to analyze the existing data within ShipFlow:\n",
      "\n",
      "---\n",
      "\n",
      "### Strategies for Data Analysis within ShipFlow\n",
      "\n",
      "The analysis of ShipFlow's data should aim to achieve several goals: optimize shipping operations, enhance user experience, refine the product, and drive business value.\n",
      "\n",
      "**1. Operational Efficiency & Bottleneck Identification Analysis**\n",
      "\n",
      "*   **Purpose:** To pinpoint inefficiencies in the shipping process, identify common delays, and understand the lifecycle of a shipment within and outside ShipFlow.\n",
      "*   **Key Data Sources:**\n",
      "    *   `Shipment Data`: Tracking events, actual vs. estimated times (pickup, customs, transit, delivery), carrier performance data.\n",
      "    *   `Exception Data`: Records of delays, customs holds, damaged goods, missed milestones.\n",
      "    *   `Task/Milestone Completion Data`: Time taken for internal tasks (document approval, payment processing).\n",
      "*   **Specific Analyses:**\n",
      "    *   **Average Transit Time Analysis:** Compare average transit times by carrier, route, goods type, and service level against planned times.\n",
      "    *   **Milestone Deviation Analysis:** Identify which specific milestones (e.g., \"Customs Cleared,\" \"Out for Delivery\") most frequently experience delays or exceptions.\n",
      "    *   **Exception Root Cause Analysis:** Group exceptions by type, carrier, and time, then drill down to understand common underlying causes (e.g., \"Documentation issues at port X,\" \"Carrier Y consistently misses pickup windows in region Z\").\n",
      "    *   **Cycle Time Analysis:** Measure the end-to-end time from shipment creation to final delivery, segmenting by various criteria to find bottlenecks.\n",
      "*   **Actionable Insights:**\n",
      "    *   Identify underperforming carriers or routes.\n",
      "    *   Optimize internal processes (e.g., streamline document approval if it's a bottleneck).\n",
      "    *   Proactively address recurring customs issues with specific brokers or regions.\n",
      "    *   Refine estimated delivery times for greater accuracy.\n",
      "\n",
      "**2. User Behavior & Feature Engagement Analysis**\n",
      "\n",
      "*   **Purpose:** To understand how users interact with ShipFlow, which features are most valuable, and where users might be struggling or disengaging. This helps in product development and UX improvements.\n",
      "*   **Key Data Sources:**\n",
      "    *   `User Interaction Data`: Clicks, page views, time spent on features, search queries, filter usage.\n",
      "    *   `Communication Hub Data`: Number of messages sent, participants, resolution times for issues discussed in-app.\n",
      "    *   `Document Management Data`: Frequency of document uploads, downloads, sharing, versioning.\n",
      "    *   `Feature Adoption Metrics`: Which roles use which features, frequency of use.\n",
      "*   **Specific Analyses:**\n",
      "    *   **Feature Usage Funnels:** Map user journeys through key workflows (e.g., \"create new shipment,\" \"upload document,\" \"check status\") to identify drop-off points.\n",
      "    *   **Stickiness & Churn Analysis:** Monitor daily/weekly active users, and identify features correlating with high engagement vs. disengagement.\n",
      "    *   **Search & Filter Effectiveness:** Analyze common search terms and filter usage to improve navigation and information retrieval.\n",
      "    *   **Collaboration Pattern Analysis:** Observe communication volumes and patterns within specific project spaces – are they effective, or are users reverting to external tools?\n",
      "*   **Actionable Insights:**\n",
      "    *   Prioritize development for highly used features or neglected but critical ones.\n",
      "    *   Simplify complex workflows identified by drop-offs.\n",
      "    *   Improve onboarding for underutilized features.\n",
      "    *   Tailor notifications and alerts based on user roles and preferences.\n",
      "\n",
      "**3. Cost Optimization & Budget Adherence Analysis**\n",
      "\n",
      "*   **Purpose:** To ensure shipments are cost-effective, identify areas for savings, and track adherence to budgets.\n",
      "*   **Key Data Sources:**\n",
      "    *   `Cost & Budget Tracking Data`: Planned vs. actual costs per shipment/project, breakdown by carrier, service, fees (customs, storage, etc.).\n",
      "    *   `Carrier Pricing Data`: Negotiated rates vs. spot rates used.\n",
      "    *   `Invoice Data`: Discrepancies between carrier invoices and planned costs.\n",
      "*   **Specific Analyses:**\n",
      "    *   **Cost Variance Analysis:** Compare actual costs against budgeted costs for individual shipments and projects, identifying major overruns.\n",
      "    *   **Carrier Cost-Effectiveness:** Evaluate total cost per shipment/route by carrier against their on-time performance and service quality.\n",
      "    *   **Surcharge & Fee Analysis:** Identify frequently incurred surcharges or unexpected fees and their prevalence.\n",
      "    *   **Budget vs. Actual Spend Trend:** Monitor spending patterns over time to identify seasonal trends or areas of increasing costs.\n",
      "*   **Actionable Insights:**\n",
      "    *   Negotiate better rates with specific carriers or for certain routes/services.\n",
      "    *   Optimize carrier selection based on a cost-performance matrix.\n",
      "    *   Identify opportunities to consolidate shipments or adjust shipping modes.\n",
      "    *   Improve accuracy of initial budget estimations.\n",
      "\n",
      "**4. Risk & Proactive Alerting Efficacy Analysis**\n",
      "\n",
      "*   **Purpose:** To assess the effectiveness of ShipFlow's proactive alerting system and identify patterns in risks to better mitigate them.\n",
      "*   **Key Data Sources:**\n",
      "    *   `Alerting System Logs`: What alerts were triggered, to whom, and when.\n",
      "    *   `Exception Management Data`: How exceptions were resolved, time to resolution, impact.\n",
      "    *   `External Event Data`: Weather alerts, port strikes (if integrated or manually logged).\n",
      "*   **Specific Analyses:**\n",
      "    *   **Alert-to-Resolution Time:** Measure the time from an alert being triggered to the related issue being resolved or mitigated.\n",
      "    *   **False Positive Rate:** Analyze how many alerts are triggered but don't lead to actual problems, indicating potential calibration issues.\n",
      "    *   **Impact of Early Alerts:** Correlate early alerts with reduced negative impact (e.g., did an early customs hold alert prevent a larger delay?).\n",
      "    *   **Risk Pattern Identification:** Identify common sequences of events that precede major issues (e.g., \"documentation delay\" often followed by \"customs hold\").\n",
      "*   **Actionable Insights:**\n",
      "    *   Refine alert rules and thresholds for better accuracy and relevance.\n",
      "    *   Automate responses to common, low-severity alerts.\n",
      "    *   Develop playbooks for handling high-frequency, high-impact risks based on historical data.\n",
      "\n",
      "**5. Integrations & Data Reliability Assessment**\n",
      "\n",
      "*   **Purpose:** To ensure the stability and accuracy of data flowing into ShipFlow from external carriers and other systems.\n",
      "*   **Key Data Sources:**\n",
      "    *   `Integration Logs`: API call success/failure rates, data sync times, error messages.\n",
      "    *   `Tracking Data Discrepancies`: Instances where ShipFlow's tracking data diverges from a carrier's official website.\n",
      "    *   `User Feedback on Data Accuracy`: Reports from users about incorrect information.\n",
      "*   **Specific Analyses:**\n",
      "    *   **API Error Rate Monitoring:** Track the frequency and types of errors for each carrier API.\n",
      "    *   **Data Latency Analysis:** Measure the delay between a carrier update and its reflection in ShipFlow.\n",
      "    *   **Data Inconsistency Reports:** Automatically or manually flag discrepancies between integrated data and expected values.\n",
      "*   **Actionable Insights:**\n",
      "    *   Prioritize maintenance and upgrades for problematic integrations.\n",
      "    *   Develop better error handling and reconciliation processes.\n",
      "    *   Communicate data limitations to users or provide alternative sources when integrations are unstable.\n",
      "\n",
      "**6. Predictive Analytics for Proactive Management**\n",
      "\n",
      "*   **Purpose:** To move beyond reactive management and leverage historical data to forecast future events, such as potential delays, cost overruns, or specific risks.\n",
      "*   **Key Data Sources:**\n",
      "    *   `Historical Shipment Data`: All tracking, exception, and cost data over time.\n",
      "    *   `External Contextual Data`: Weather patterns, holiday schedules, geopolitical events (if ingested).\n",
      "*   **Specific Analyses:**\n",
      "    *   **Estimated Time of Arrival (ETA) Refinement:** Use machine learning models to predict more accurate ETAs based on historical data, carrier performance, route specifics, and known variables.\n",
      "    *   **Delay Probability Prediction:** Predict the likelihood of a shipment experiencing a delay based on its characteristics (carrier, origin, destination, goods type, time of year).\n",
      "    *   **Customs Hold Risk Assessment:** Predict which shipments are at higher risk of customs holds based on historical data for specific routes, goods, or documentation patterns.\n",
      "    *   **Cost Fluctuation Forecasting:** Forecast potential cost increases or surcharges based on historical trends and external factors.\n",
      "*   **Actionable Insights:**\n",
      "    *   Proactively re-route shipments, allocate additional resources, or prepare alternative plans if a high-risk delay is predicted.\n",
      "    *   Adjust customer expectations with more accurate delivery windows.\n",
      "    *   Implement dynamic pricing or insurance recommendations based on predicted risk.\n",
      "\n",
      "---\n",
      "\n",
      "By systematically applying these data analysis strategies, ShipFlow can not only fulfill its promise of streamlining shipping project management but also continuously evolve as an intelligent, predictive, and indispensable tool for logistics professionals.\n",
      "********************************************************************************\n",
      "(<class 'autogen_agentchat.messages.TextMessage'>\n",
      "********************************************************************************\n",
      "[MarketingAgent] This is an incredibly thorough and well-articulated breakdown of ShipFlow's data analysis strategies. It demonstrates a deep understanding of how to leverage product data not just for internal improvement but also to drive tangible value for users by optimizing their shipping operations. The move towards predictive analytics is particularly exciting and truly differentiates ShipFlow as an intelligent platform.\n",
      "\n",
      "Now, with such a robust product concept and a clear vision for data-driven continuous improvement, let's talk about bringing ShipFlow to market.\n",
      "\n",
      "To initiate a marketing campaign for **ShipFlow**, could you please specify the **budget** you have in mind for this campaign? Once I have that, I can leverage my expertise to kickstart the launch and promotion of this innovative shipping project management solution.\n",
      "********************************************************************************\n",
      "(<class 'autogen_agentchat.base._task.TaskResult'>\n",
      "messages=[TextMessage(id='0eb539a9-7a87-4671-ae25-d183d9d47bfb', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 12, 30, 3, 43, 11, 979838, tzinfo=datetime.timezone.utc), content='Come up with an shipping product idea for shipping related project management', type='TextMessage'), TextMessage(id='8c9a1ec4-9271-4e5d-8918-0200cb9fe975', source='EngineeringAgent', models_usage=RequestUsage(prompt_tokens=97, completion_tokens=642), metadata={}, created_at=datetime.datetime(2025, 12, 30, 3, 43, 18, 988721, tzinfo=datetime.timezone.utc), content='Here\\'s a shipping product idea for shipping-related project management:\\n\\n**Product Name:** ShipFlow\\n\\n**Concept:** ShipFlow is a unified, intelligent project management platform designed specifically for the complexities of global and domestic shipping. It transforms chaotic shipment tracking and communication into a streamlined, collaborative workflow.\\n\\n**Core Features:**\\n\\n1.  **Centralized Shipment Dashboard:**\\n    *   A single pane of glass showing the status of all active shipments across multiple carriers.\\n    *   Visual timelines for each shipment, highlighting key milestones (pickup, in transit, customs, delivery).\\n    *   Quick filters and search to locate specific shipments or projects.\\n\\n2.  **Multi-Carrier Integration & Real-time Tracking:**\\n    *   Connects seamlessly with major global and local carriers (e.g., FedEx, UPS, DHL, Maersk, local freight forwarders).\\n    *   Aggregates real-time tracking data, providing consistent updates regardless of the carrier.\\n    *   Automated status updates and estimated delivery time predictions.\\n\\n3.  **Collaborative Project Spaces:**\\n    *   Create dedicated \"Shipping Projects\" for large consignments, specific clients, or complex routes.\\n    *   Invite internal teams, clients, and external partners (e.g., customs brokers, freight forwarders) to a shared workspace.\\n    *   Role-based access controls to manage permissions.\\n\\n4.  **Integrated Document Management:**\\n    *   Securely upload, store, and share all essential shipping documents (Bills of Lading, Commercial Invoices, Packing Lists, Customs Declarations, Permits).\\n    *   Version control for documents and audit trails of who accessed or modified them.\\n    *   Automated reminders for expiring documents or required submissions.\\n\\n5.  **Communication Hub:**\\n    *   In-app messaging tied directly to specific shipments or projects.\\n    *   Reduces reliance on external emails, keeping all communication contextual and easily searchable.\\n    *   Notification system for critical updates, delays, or required actions.\\n\\n6.  **Proactive Alerting & Exception Management:**\\n    *   Configurable alerts for deviations from the planned schedule (e.g., customs hold, missed delivery window, weather delays).\\n    *   Automated suggestions for corrective actions or stakeholder notifications when an exception occurs.\\n\\n7.  **Cost & Budget Tracking:**\\n    *   Track actual shipping costs against planned budgets for each project.\\n    *   Breakdown of costs by carrier, route, and service type.\\n    *   Reporting tools to identify cost-saving opportunities.\\n\\n8.  **Analytics & Reporting:**\\n    *   Dashboards showing key performance indicators (KPIs) like on-time delivery rates, average transit times, carrier performance.\\n    *   Customizable reports to analyze shipping efficiency, identify bottlenecks, and inform future logistics strategies.\\n\\n**Value Proposition:** ShipFlow centralizes and automates the most challenging aspects of shipping project management, leading to improved operational efficiency, reduced delays, enhanced communication, and better cost control for businesses handling significant volumes of freight.', type='TextMessage'), TextMessage(id='907a1c23-fa89-4729-9fd3-23aa2aef5041', source='DataScientistAgent', models_usage=RequestUsage(prompt_tokens=670, completion_tokens=2024), metadata={}, created_at=datetime.datetime(2025, 12, 30, 3, 43, 33, 740543, tzinfo=datetime.timezone.utc), content='This is an excellent and comprehensive product idea, ShipFlow, addressing a critical need in logistics project management. The core features cover the essential aspects, and the value proposition is clear.\\n\\nNow, let\\'s pivot to how we would analyze the data generated by and flowing through ShipFlow to continuously improve the product, its adoption, and the efficiency of the shipping operations it manages.\\n\\nHere are strategies to analyze the existing data within ShipFlow:\\n\\n---\\n\\n### Strategies for Data Analysis within ShipFlow\\n\\nThe analysis of ShipFlow\\'s data should aim to achieve several goals: optimize shipping operations, enhance user experience, refine the product, and drive business value.\\n\\n**1. Operational Efficiency & Bottleneck Identification Analysis**\\n\\n*   **Purpose:** To pinpoint inefficiencies in the shipping process, identify common delays, and understand the lifecycle of a shipment within and outside ShipFlow.\\n*   **Key Data Sources:**\\n    *   `Shipment Data`: Tracking events, actual vs. estimated times (pickup, customs, transit, delivery), carrier performance data.\\n    *   `Exception Data`: Records of delays, customs holds, damaged goods, missed milestones.\\n    *   `Task/Milestone Completion Data`: Time taken for internal tasks (document approval, payment processing).\\n*   **Specific Analyses:**\\n    *   **Average Transit Time Analysis:** Compare average transit times by carrier, route, goods type, and service level against planned times.\\n    *   **Milestone Deviation Analysis:** Identify which specific milestones (e.g., \"Customs Cleared,\" \"Out for Delivery\") most frequently experience delays or exceptions.\\n    *   **Exception Root Cause Analysis:** Group exceptions by type, carrier, and time, then drill down to understand common underlying causes (e.g., \"Documentation issues at port X,\" \"Carrier Y consistently misses pickup windows in region Z\").\\n    *   **Cycle Time Analysis:** Measure the end-to-end time from shipment creation to final delivery, segmenting by various criteria to find bottlenecks.\\n*   **Actionable Insights:**\\n    *   Identify underperforming carriers or routes.\\n    *   Optimize internal processes (e.g., streamline document approval if it\\'s a bottleneck).\\n    *   Proactively address recurring customs issues with specific brokers or regions.\\n    *   Refine estimated delivery times for greater accuracy.\\n\\n**2. User Behavior & Feature Engagement Analysis**\\n\\n*   **Purpose:** To understand how users interact with ShipFlow, which features are most valuable, and where users might be struggling or disengaging. This helps in product development and UX improvements.\\n*   **Key Data Sources:**\\n    *   `User Interaction Data`: Clicks, page views, time spent on features, search queries, filter usage.\\n    *   `Communication Hub Data`: Number of messages sent, participants, resolution times for issues discussed in-app.\\n    *   `Document Management Data`: Frequency of document uploads, downloads, sharing, versioning.\\n    *   `Feature Adoption Metrics`: Which roles use which features, frequency of use.\\n*   **Specific Analyses:**\\n    *   **Feature Usage Funnels:** Map user journeys through key workflows (e.g., \"create new shipment,\" \"upload document,\" \"check status\") to identify drop-off points.\\n    *   **Stickiness & Churn Analysis:** Monitor daily/weekly active users, and identify features correlating with high engagement vs. disengagement.\\n    *   **Search & Filter Effectiveness:** Analyze common search terms and filter usage to improve navigation and information retrieval.\\n    *   **Collaboration Pattern Analysis:** Observe communication volumes and patterns within specific project spaces – are they effective, or are users reverting to external tools?\\n*   **Actionable Insights:**\\n    *   Prioritize development for highly used features or neglected but critical ones.\\n    *   Simplify complex workflows identified by drop-offs.\\n    *   Improve onboarding for underutilized features.\\n    *   Tailor notifications and alerts based on user roles and preferences.\\n\\n**3. Cost Optimization & Budget Adherence Analysis**\\n\\n*   **Purpose:** To ensure shipments are cost-effective, identify areas for savings, and track adherence to budgets.\\n*   **Key Data Sources:**\\n    *   `Cost & Budget Tracking Data`: Planned vs. actual costs per shipment/project, breakdown by carrier, service, fees (customs, storage, etc.).\\n    *   `Carrier Pricing Data`: Negotiated rates vs. spot rates used.\\n    *   `Invoice Data`: Discrepancies between carrier invoices and planned costs.\\n*   **Specific Analyses:**\\n    *   **Cost Variance Analysis:** Compare actual costs against budgeted costs for individual shipments and projects, identifying major overruns.\\n    *   **Carrier Cost-Effectiveness:** Evaluate total cost per shipment/route by carrier against their on-time performance and service quality.\\n    *   **Surcharge & Fee Analysis:** Identify frequently incurred surcharges or unexpected fees and their prevalence.\\n    *   **Budget vs. Actual Spend Trend:** Monitor spending patterns over time to identify seasonal trends or areas of increasing costs.\\n*   **Actionable Insights:**\\n    *   Negotiate better rates with specific carriers or for certain routes/services.\\n    *   Optimize carrier selection based on a cost-performance matrix.\\n    *   Identify opportunities to consolidate shipments or adjust shipping modes.\\n    *   Improve accuracy of initial budget estimations.\\n\\n**4. Risk & Proactive Alerting Efficacy Analysis**\\n\\n*   **Purpose:** To assess the effectiveness of ShipFlow\\'s proactive alerting system and identify patterns in risks to better mitigate them.\\n*   **Key Data Sources:**\\n    *   `Alerting System Logs`: What alerts were triggered, to whom, and when.\\n    *   `Exception Management Data`: How exceptions were resolved, time to resolution, impact.\\n    *   `External Event Data`: Weather alerts, port strikes (if integrated or manually logged).\\n*   **Specific Analyses:**\\n    *   **Alert-to-Resolution Time:** Measure the time from an alert being triggered to the related issue being resolved or mitigated.\\n    *   **False Positive Rate:** Analyze how many alerts are triggered but don\\'t lead to actual problems, indicating potential calibration issues.\\n    *   **Impact of Early Alerts:** Correlate early alerts with reduced negative impact (e.g., did an early customs hold alert prevent a larger delay?).\\n    *   **Risk Pattern Identification:** Identify common sequences of events that precede major issues (e.g., \"documentation delay\" often followed by \"customs hold\").\\n*   **Actionable Insights:**\\n    *   Refine alert rules and thresholds for better accuracy and relevance.\\n    *   Automate responses to common, low-severity alerts.\\n    *   Develop playbooks for handling high-frequency, high-impact risks based on historical data.\\n\\n**5. Integrations & Data Reliability Assessment**\\n\\n*   **Purpose:** To ensure the stability and accuracy of data flowing into ShipFlow from external carriers and other systems.\\n*   **Key Data Sources:**\\n    *   `Integration Logs`: API call success/failure rates, data sync times, error messages.\\n    *   `Tracking Data Discrepancies`: Instances where ShipFlow\\'s tracking data diverges from a carrier\\'s official website.\\n    *   `User Feedback on Data Accuracy`: Reports from users about incorrect information.\\n*   **Specific Analyses:**\\n    *   **API Error Rate Monitoring:** Track the frequency and types of errors for each carrier API.\\n    *   **Data Latency Analysis:** Measure the delay between a carrier update and its reflection in ShipFlow.\\n    *   **Data Inconsistency Reports:** Automatically or manually flag discrepancies between integrated data and expected values.\\n*   **Actionable Insights:**\\n    *   Prioritize maintenance and upgrades for problematic integrations.\\n    *   Develop better error handling and reconciliation processes.\\n    *   Communicate data limitations to users or provide alternative sources when integrations are unstable.\\n\\n**6. Predictive Analytics for Proactive Management**\\n\\n*   **Purpose:** To move beyond reactive management and leverage historical data to forecast future events, such as potential delays, cost overruns, or specific risks.\\n*   **Key Data Sources:**\\n    *   `Historical Shipment Data`: All tracking, exception, and cost data over time.\\n    *   `External Contextual Data`: Weather patterns, holiday schedules, geopolitical events (if ingested).\\n*   **Specific Analyses:**\\n    *   **Estimated Time of Arrival (ETA) Refinement:** Use machine learning models to predict more accurate ETAs based on historical data, carrier performance, route specifics, and known variables.\\n    *   **Delay Probability Prediction:** Predict the likelihood of a shipment experiencing a delay based on its characteristics (carrier, origin, destination, goods type, time of year).\\n    *   **Customs Hold Risk Assessment:** Predict which shipments are at higher risk of customs holds based on historical data for specific routes, goods, or documentation patterns.\\n    *   **Cost Fluctuation Forecasting:** Forecast potential cost increases or surcharges based on historical trends and external factors.\\n*   **Actionable Insights:**\\n    *   Proactively re-route shipments, allocate additional resources, or prepare alternative plans if a high-risk delay is predicted.\\n    *   Adjust customer expectations with more accurate delivery windows.\\n    *   Implement dynamic pricing or insurance recommendations based on predicted risk.\\n\\n---\\n\\nBy systematically applying these data analysis strategies, ShipFlow can not only fulfill its promise of streamlining shipping project management but also continuously evolve as an intelligent, predictive, and indispensable tool for logistics professionals.', type='TextMessage'), TextMessage(id='a259f836-48ca-435e-a3f2-214d530933dc', source='MarketingAgent', models_usage=RequestUsage(prompt_tokens=2763, completion_tokens=151), metadata={}, created_at=datetime.datetime(2025, 12, 30, 3, 43, 36, 799246, tzinfo=datetime.timezone.utc), content=\"This is an incredibly thorough and well-articulated breakdown of ShipFlow's data analysis strategies. It demonstrates a deep understanding of how to leverage product data not just for internal improvement but also to drive tangible value for users by optimizing their shipping operations. The move towards predictive analytics is particularly exciting and truly differentiates ShipFlow as an intelligent platform.\\n\\nNow, with such a robust product concept and a clear vision for data-driven continuous improvement, let's talk about bringing ShipFlow to market.\\n\\nTo initiate a marketing campaign for **ShipFlow**, could you please specify the **budget** you have in mind for this campaign? Once I have that, I can leverage my expertise to kickstart the launch and promotion of this innovative shipping project management solution.\", type='TextMessage')] stop_reason='Maximum number of turns 3 reached.'\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T03:20:30.508461Z",
     "start_time": "2025-12-30T03:20:18.855281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def initiate_marketing_campaign(product_name: str, budget: float) -> str:\n",
    "    \"\"\"Initiates a marketing campaign for a given product within the specified budget.\"\"\"\n",
    "    return f\"Marketing campaign for {product_name} has been initiated with a budget of ${budget:.2f}.\"\n",
    "\n",
    "\n",
    "marketting_head = AssistantAgent(\n",
    "    name=\"MarketingAgent\",\n",
    "    description=\"Marketing Head.\",\n",
    "    system_message=\"You are a expert marketing agent who come up with ideas to sell products effectively.\",\n",
    "    model_client=gemini_client,\n",
    "    tools=[initiate_marketing_campaign]\n",
    ")\n",
    "chief_data_scientist = AssistantAgent(\n",
    "    name=\"DataScientistAgent\",\n",
    "    description=\"Chief Data Scientist.\",\n",
    "        system_message=\"You are able to come up with strategies to Analyse existing Data.\",\n",
    "    model_client=gemini_client\n",
    ")\n",
    "engineering_head = AssistantAgent(\n",
    "    name=\"EngineeringAgent\",\n",
    "    description=\"CTO.\",\n",
    "    system_message=\"You are able to come up with new Ideas and come up with Engineering solutions to it.\",\n",
    "    model_client=gemini_client,\n",
    "    tools=[initiate_marketing_campaign]\n",
    ")\n",
    "team = Swarm(\n",
    "    participants=[engineering_head, chief_data_scientist, marketting_head],\n",
    "    max_turns=3\n",
    ")\n",
    "result = await team.run(task=\"Come up with an shipping product idea for shipping related project management\")\n",
    "for message in result.messages:\n",
    "    print(f\"{'*' * 80}\\n[{message.source}]: {message.content}\")\n"
   ],
   "id": "62cef4c6c3fa6859",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[user]: Come up with an shipping product idea for shipping related project management\n",
      "********************************************************************************\n",
      "[EngineeringAgent]: Here's a shipping product idea:\n",
      "\n",
      "**Product Name: ShipFlow PM**\n",
      "\n",
      "**Concept:** ShipFlow PM is an AI-powered project management platform specifically designed for the complexities of the shipping and logistics industry. It aims to streamline operations, reduce delays, and improve communication across all stakeholders in a shipping project, from planning to final delivery.\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "1.  **Intelligent Route Optimization & Scheduling:**\n",
      "    *   **AI-driven analysis:** Leverages real-time data (weather, traffic, port congestion, carrier availability) to suggest the most efficient and cost-effective routes for multi-modal shipments.\n",
      "    *   **Dynamic scheduling:** Automatically adjusts timelines and alerts stakeholders to potential delays or opportunities for faster delivery.\n",
      "    *   **Capacity utilization:** Optimizes container and vehicle loading plans to maximize space and reduce costs.\n",
      "\n",
      "2.  **Predictive Delay & Risk Management:**\n",
      "    *   **Proactive alerts:** Uses machine learning to predict potential delays due to unforeseen circumstances (e.g., customs issues, port strikes, extreme weather) and provides early warnings.\n",
      "    *   **Scenario planning:** Offers alternative routing or contingency plans when risks are identified.\n",
      "    *   **Compliance checker:** Automatically flags potential regulatory or documentation issues before they cause delays.\n",
      "\n",
      "3.  **Automated Documentation & Compliance:**\n",
      "    *   **Smart document generation:** Auto-populates and generates necessary shipping documents (Bills of Lading, customs declarations, manifests) based on project data.\n",
      "    *   **Digital repository:** Centralized, secure storage for all shipping-related documents, easily accessible for audits and collaboration.\n",
      "    *   **Regulatory updates:** Automatically tracks and applies the latest international and local shipping regulations to ensure compliance.\n",
      "\n",
      "4.  **Real-time Tracking & Visibility:**\n",
      "    *   **Unified Dashboard:** Provides a single pane of glass to track all shipments across different carriers, modes of transport, and geographical locations.\n",
      "    *   **Milestone tracking:** Visual progress tracking against key project milestones (e.g., departure, customs clearance, arrival at port, final delivery).\n",
      "    *   **Stakeholder Portal:** Customizable views for clients, suppliers, and partners to track the status of their specific shipments without needing full project access.\n",
      "\n",
      "5.  **Collaborative Communication & Workflow:**\n",
      "    *   **Centralized communication hub:** Dedicated chat, task assignments, and discussion forums for each shipping project, reducing email clutter.\n",
      "    *   **Workflow automation:** Automates repetitive tasks like approval processes, notification triggers, and data entry.\n",
      "    *   **Performance analytics:** Provides insights into carrier performance, delivery times, cost variances, and operational efficiency to drive continuous improvement.\n",
      "\n",
      "**Target Audience:** Freight forwarders, logistics departments of large enterprises, e-commerce businesses with complex supply chains, and shipping agencies.\n",
      "\n",
      "This product aims to bring a new level of intelligence and efficiency to shipping project management, moving beyond traditional tracking to proactive problem-solving and streamlined collaboration.\n",
      "********************************************************************************\n",
      "[EngineeringAgent]: \n",
      "********************************************************************************\n",
      "[EngineeringAgent]: \n",
      "\n"
     ]
    }
   ],
   "execution_count": 76
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
