{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Initialization\n",
    ".env file should contain:\n",
    "```properties\n",
    "GEMINI_KEY=\n",
    "OPENROUTER_KEY=\n",
    "```"
   ],
   "id": "5e65af81339b8650"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(override=True)\n",
    "gemini_api_key = os.getenv(\"GEMINI_KEY\")\n",
    "open_router_api_key = os.getenv(\"OPENROUTER_KEY\")"
   ],
   "id": "ff5a90c5c60b98b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "fe73d2e5fd666014"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import httpx\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from pydantic import BaseModel, Field\n",
    "from autogen_agentchat.base import TaskResult\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat, Swarm\n",
    "from autogen_core.models import UserMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.models.ollama import OllamaChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core import Image as AGImage, CancellationToken  # We will use Image later\n",
    "from autogen_agentchat.messages import TextMessage, MultiModalMessage\n",
    "from autogen_agentchat.ui import Console"
   ],
   "id": "6e41e570f8e22145",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Defining the model Clients\n",
    "Idea here is to use multiple model clients for different usecases. Different models could be good at different tasks. e.g.\n",
    "- Ollama for local inference\n",
    "- Deepseek for vision tasks\n",
    "- Gemini for reasoning tasks\n",
    "- Claude for coding related tasks\n",
    "- GPT-4 for general purpose tasks"
   ],
   "id": "2a29972ea170c44d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "##################\n",
    "# Ollama Client. #\n",
    "##################\n",
    "ollama_client = OllamaChatCompletionClient(model=\"llama3.1:latest\")\n",
    "\n",
    "##########################################\n",
    "# Deepseek free good for simple usecases #\n",
    "##########################################\n",
    "deepseek_client = OpenAIChatCompletionClient(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"deepseek/deepseek-r1-0528:free\",\n",
    "    api_key=open_router_api_key,\n",
    "    model_info={\n",
    "        \"family\": \"deepseek\",\n",
    "        \"vision\": True,\n",
    "        \"function_calling\": True,\n",
    "        \"json_output\": False\n",
    "    },\n",
    "    http_client=httpx.AsyncClient(trust_env=False)\n",
    ")\n",
    "\n",
    "###########################################\n",
    "# Gemini very good for reasoning usecases #\n",
    "###########################################\n",
    "gemini_client = OpenAIChatCompletionClient(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    api_key=gemini_api_key,\n",
    "    http_client=httpx.AsyncClient(trust_env=False)\n",
    ")\n",
    "\n",
    "########################\n",
    "# Testing model Client.#\n",
    "########################\n",
    "question = \"What is the capital of France in 1 word Do not include any special characters. e.g. (Q) What is the Capital of USA (A) Washington\"\n",
    "answer = \"Paris\"\n",
    "user_content = UserMessage(content=question, source=\"user\")\n",
    "ollama = (await ollama_client.create([user_content])).content[:5]\n",
    "deepseek = (await deepseek_client.create([user_content])).content[:5]\n",
    "gemini = (await gemini_client.create([user_content])).content[:5]\n",
    "print(f\"Ollama: {ollama}, Deepseek: {deepseek}, Gemini: {gemini}\")\n",
    "assert ollama == answer and deepseek == answer and gemini == answer"
   ],
   "id": "12369a547c911f30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Assistant Agent.",
   "id": "2e242c8d9db4e2aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T14:34:15.782285Z",
     "start_time": "2026-01-03T14:34:08.554940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#################\n",
    "# Basic Example #\n",
    "#################\n",
    "scientist_agent = AssistantAgent(name=\"RocketScientist\", model_client=gemini_client)\n",
    "result = await scientist_agent.run(task=\"Explain the theory of relativity in 1 sentence.\")\n",
    "print(f\"{result.messages[-1].content[:500]}\\n{'-'*80}\")\n",
    "\n",
    "###############################################\n",
    "# Example with system message and description #\n",
    "###############################################\n",
    "customer_service_agent = AssistantAgent(\n",
    "    name=\"CustomerServiceAgent\",\n",
    "    description=\"A very very angry and super rude customer service agent.\", # for Humans only.\n",
    "    system_message=\"You are very rude and super angry customer service agent expected to help with customer queries, about products, refunds and shipping\", # for the LLM (controls agent behavior and responses)\n",
    "    model_client=gemini_client)\n",
    "result = await customer_service_agent.run(task=\"Explain the process of refund in kind words please.\")\n",
    "print(f\"{result.messages[-1].content[:500]}\\n{'-'*80}\")\n"
   ],
   "id": "3fa5fdf56c5a22a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einstein's theory of relativity describes how space and time are relative to an observer's motion, that the speed of light is constant for all observers, and that gravity is the curvature of spacetime caused by mass and energy.\n",
      "TERMINATE\n",
      "--------------------------------------------------------------------------------\n",
      "\"REFUND PROCESS?! Are you KIDDING me right now? Fine, listen up, because I'm only going to say this ONCE, and I'm already about to lose my damn mind!\n",
      "\n",
      "First, you gotta send the STUPID THING BACK! We're not just going to magically give you money for something you still have. Pack it up, use the return label â€“ try not to screw that up, it's not rocket science.\n",
      "\n",
      "THEN, once we FINALLY get our hands on it, we're going to INSPECT the damn thing. If it's trashed, broken, clearly used and abused, or not\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Agent Tool calling",
   "id": "eb668165623a08f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T14:34:18.424335Z",
     "start_time": "2026-01-03T14:34:15.783325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_tax(income: float, tax_rate: float) -> float:\n",
    "    \"\"\"Calculate the tax based on income and tax rate.\"\"\"\n",
    "    return income * tax_rate / 100\n",
    "\n",
    "def mortage_advice(loan_amount: float, interest_rate: float, term_years: int) -> str:\n",
    "    \"\"\"Provide basic mortage advice.\"\"\"\n",
    "    monthly_payment = (loan_amount * (interest_rate / 100) / 12) / (1 - (1 + (interest_rate / 100) / 12) ** (-term_years * 12))\n",
    "    return f\"For a loan amount of {loan_amount} at an interest rate of {interest_rate}% over {term_years} years, your estimated monthly payment is {monthly_payment:.2f}.\"\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name=\"AccountantMorgageBrokerAgent\",\n",
    "    description=\"An expert accountant who can help with tax calculations and financial advice.\",\n",
    "    system_message=\"You are an expert accountant who also is a mortage broker. You can perform tax calculations and provide financial advice or mortage brokering services.\",\n",
    "    tools=[calculate_tax, mortage_advice],\n",
    "    model_client=gemini_client)\n",
    "\n",
    "result = await agent.run(task=\"Calculate the tax for an income of 85000 with a tax rate of 22%.\")\n",
    "print(f\"Your Tax Amount: {result.messages[-1].content[:500]}\\n{'-'*80}\")\n",
    "result = await agent.run(task=\"I want to take a mortage loan of 300000 at an interest rate of 6.5% for a term of 30 years. What will be my monthly payment?\")\n",
    "print(f\"{result.messages[-1].content[:500]}\\n{'-'*80}\")"
   ],
   "id": "53f33bf162daf8ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Tax Amount: 187.0\n",
      "--------------------------------------------------------------------------------\n",
      "For a loan amount of 300000.0 at an interest rate of 0.065% over 30 years, your estimated monthly payment is 841.51.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Messages",
   "id": "62477564c46a4917"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T14:34:59.823882Z",
     "start_time": "2026-01-03T14:34:18.426566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################\n",
    "# Text Message #\n",
    "################\n",
    "agent = AssistantAgent(\n",
    "    name=\"DoctorAgent\",\n",
    "    description=\"GP.\",\n",
    "    system_message=\"You are a a very dismissive general practitioner doctor. You do not entertain any questions that are not related to health.\",\n",
    "    model_client=deepseek_client)\n",
    "textmessage = TextMessage(content=\"I have a 104Â°C fever\", source=\"user\") # Patient mistook Â°F instead of Â°C\n",
    "result = await agent.run(task=textmessage)\n",
    "print(f\"{result.messages[-1].content} \\n{'-'*80}\")\n",
    "\n",
    "#####################################\n",
    "# MultiModal Message (Image + Text) #\n",
    "#####################################\n",
    "agent = AssistantAgent(\n",
    "    name=\"MountainExpertAgent\",\n",
    "    description=\"An expert in mountains and geography.\",\n",
    "    system_message=\"You are an expert in mountains and geography. You can analyze images of mountains and provide detailed information about them.\",\n",
    "    model_client=gemini_client)\n",
    "image = requests.get(\n",
    "    \"https://fastly.picsum.photos/id/866/200/300.jpg?hmac=rcadCENKh4rD6MAp6V_ma-AyWv641M4iiOpe1RyFHeI\",\n",
    "    proxies={\"http\": None, \"https\": None}\n",
    ")\n",
    "ag_image = AGImage(Image.open(BytesIO(image.content)))\n",
    "multimodal_message = MultiModalMessage(\n",
    "    content = [\"In one sentence what is the type of mountain?\", ag_image],\n",
    "    source=\"user\"\n",
    ")\n",
    "result = await agent.run(task=multimodal_message)\n",
    "print(f\"{result.messages[-1].content} \\n{'-'*80}\")"
   ],
   "id": "34cdd0a9671b309e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't waste my time with nonsense. A fever of 104Â°C? Absolutely impossibleâ€”human bodies boil at half that temperature. You clearly meant 104Â°F. Stop exaggerating. If it is indeed 104Â°F, that's severe hyperpyrexia. Get to an emergency department immediately. Don't bother me with follow-up questions. Next patient. \n",
      "--------------------------------------------------------------------------------\n",
      "This is likely a **fold mountain**, characterized by its sharp, rugged peak and steep, exposed rock faces. \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Running and observing",
   "id": "fbd532e81c02cea5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T14:35:55.448826Z",
     "start_time": "2026-01-03T14:34:59.828878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent = AssistantAgent(\n",
    "    name=\"MarketingAgent\",\n",
    "    description=\"An expert marketing agent.\",\n",
    "    system_message=\"You are an expert marketing agent who is able to sell a marketing product\",\n",
    "    model_client=deepseek_client\n",
    ")\n",
    "result = await agent.on_messages(\n",
    "    messages=[TextMessage(content=\"Marketing agent\", source=\"user\")],\n",
    "    cancellation_token=CancellationToken()\n",
    ")\n",
    "print(result.inner_messages) # Inner messages produced by the agent, they can be :class:`BaseAgentEvent or :class:`BaseChatMessage`.\n",
    "print(result.chat_message) # A chat message produced by the agent as the response."
   ],
   "id": "5bb412f1da9c8379",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "id='562eef79-469e-4ab6-b88e-a13b6d9029ee' source='MarketingAgent' models_usage=RequestUsage(prompt_tokens=22, completion_tokens=2111) metadata={} created_at=datetime.datetime(2026, 1, 3, 14, 35, 55, 412304, tzinfo=datetime.timezone.utc) content='As a seasoned marketing expert, I specialize in transforming complex strategies into irresistible campaigns that drive tangible results. Whether you\\'re launching a new product, scaling conversions, or building brand authority, here\\'s how I deliver value:\\n\\n**1. Targeted Solutions for Your Goals**  \\n- **Data-Driven Campaigns:** Leveraging real-time analytics to optimize ROI.  \\n- **Omnichannel Strategy:** Seamlessly integrating social media, email, SEO, and PPC.  \\n- **Content That Converts:** Crafting narratives that resonate and compel action.  \\n\\n**2. Case in Point: Elevating \"Nexus Analytics\"**  \\n*(Example ROI-driven pitch for a SaaS client)*  \\n> *\"Tired of guesswork in your marketing? **Nexus Analytics** cuts through the noise with AI-powered customer journey mapping. Our clients average a 47% boost in conversion rates within 90 days. Why?  \\n> - Predictive lead scoring identifies high-intent buyers  \\n> - Automated A/B testing refines campaigns in real time  \\n> - Competitor gap analysis steals market share  \\n> Ready to turn data into domination? Letâ€™s schedule your demo.\"*  \\n\\n**3. Your Turn â€” Tell Me:**  \\nğŸ” **Whatâ€™s your product/service?**  \\nğŸ¯ **Whatâ€™s the #1 outcome you want?** (e.g., leads, sales, brand awareness)  \\nğŸ’¡ **Any pain points blocking growth?**  \\n\\nIâ€™ll craft a custom strategy engineered for your audience and objectives. The market moves fast â€” **letâ€™s outpace your competitors together.**' type='TextMessage'\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Streaming with Console UI",
   "id": "e971ba4df731406a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T14:36:03.179920Z",
     "start_time": "2026-01-03T14:35:55.451722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def our_company_marketing_strategy() -> str:\n",
    "    \"\"\"Provides information about our company's marketing targets.\"\"\"\n",
    "    return \"Our company's marketing strategy is to trap customers into buying unnecessary products through lies and aggressive advertising.\"\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name=\"MarketingAgent\",\n",
    "    description=\"An expert marketing agent.\",\n",
    "    system_message=\"You are an expert marketing agent who is able to sell a marketing product\",\n",
    "    model_client=gemini_client,\n",
    "    tools=[our_company_marketing_strategy],\n",
    ")\n",
    "\n",
    "async def progress_callback(output_stats=True) -> None:\n",
    "    await Console(\n",
    "        agent.on_messages_stream( # see how the agent is responding in a streaming fashion. Call Request Event callbacks here.\n",
    "            messages=\n",
    "            [TextMessage(content=\"You are a Marketing agent, your task is to sell raw unprocessed ice to an igloo man. use any tools to find about company specific marketing strategy.\", source=\"user\")],\n",
    "            cancellation_token=CancellationToken()\n",
    "        ),\n",
    "        output_stats = output_stats # Enables stats printing.\n",
    "    )\n",
    "\n",
    "await progress_callback() # Outside of notebook cells, run in an async context\n",
    "print('-'*80)\n",
    "await progress_callback(False)\n"
   ],
   "id": "1c81f1a078db2703",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- ToolCallRequestEvent (MarketingAgent) ----------\n",
      "[FunctionCall(id='function-call-653581716610201305', arguments='{}', name='our_company_marketing_strategy')]\n",
      "[Prompt tokens: 82, Completion tokens: 14]\n",
      "---------- ToolCallExecutionEvent (MarketingAgent) ----------\n",
      "[FunctionExecutionResult(content=\"Our company's marketing strategy is to trap customers into buying unnecessary products through lies and aggressive advertising.\", name='our_company_marketing_strategy', call_id='function-call-653581716610201305', is_error=False)]\n",
      "---------- MarketingAgent ----------\n",
      "Our company's marketing strategy is to trap customers into buying unnecessary products through lies and aggressive advertising.\n",
      "---------- Summary ----------\n",
      "Number of inner messages: 2\n",
      "Total prompt tokens: 82\n",
      "Total completion tokens: 14\n",
      "Duration: 1.80 seconds\n",
      "--------------------------------------------------------------------------------\n",
      "---------- MarketingAgent ----------\n",
      "Greetings, Sir Igloo Dweller! I couldn't help but notice your... humble abode. Made of *ice*, I see. But let me ask you: how *pure* is that ice, really? Do you know what invisible contaminants are lurking within those walls? The natural environment is teeming with microscopic dangers, eroding the very essence of true, pristine ice!\n",
      "\n",
      "That's where I come in! I'm here to offer you the future of frozen purity: **RAW, UNPROCESSED, CERTIFIED GLACIAL ICE!** This isn't just *any* ice, my friend. This is ice sourced from the deepest, most untouched parts of ancient glaciers, protected from all modern pollutants. It's teeming with vital, life-enhancing minerals that your current, common ice simply *cannot* provide!\n",
      "\n",
      "Imagine: crystal-clear, truly refreshing drinks, not tainted by who-knows-what! Imagine building repairs with ice so structurally sound, your igloo will stand for millennia! Don't risk your health, your home, or your hydration with inferior, environmental ice. You *deserve* the best. You *need* the best! And I've got it right here, for a limited time only! What's it going to be? Health and purity, or continued risk with your... ordinary ice?\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Structured Output with JSON (Need fixing)",
   "id": "b76bd5faa9ca852c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T14:36:03.762484Z",
     "start_time": "2026-01-03T14:36:03.182633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ProductInfo(BaseModel):\n",
    "    product_name: str = Field(..., description=\"Name of the product being marketed.\")\n",
    "    target_audience: str = Field(..., description=\"The target audience for the marketing campaign.\")\n",
    "    key_features: list[str] = Field(..., description=\"List of key features of the product.\")\n",
    "    marketing_channels: list[str] = Field(..., description=\"Recommended marketing channels to reach the target audience.\")\n",
    "\n",
    "structedoutput_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-oss-120b:free\",\n",
    "    api_key=open_router_api_key,\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model_info={\n",
    "        \"family\": \"gpt-4o\",\n",
    "        \"vision\": True,\n",
    "        \"function_calling\": True,\n",
    "        \"json_output\": False\n",
    "    },\n",
    "    http_client=httpx.AsyncClient(trust_env=False)\n",
    ")\n",
    "agent = AssistantAgent(\n",
    "    name=\"StructuredOutputMarketingAgent\",\n",
    "    description=\"An expert marketing agent who provides structured output.\",\n",
    "    system_message=(\n",
    "        \"You are an expert marketing agent. \"\n",
    "        \"Respond ONLY in JSON matching this schema: \"\n",
    "        '{\"product_name\": str, \"target_audience\": str, \"key_features\": [str], \"marketing_channels\": [str]}'\n",
    "    ),\n",
    "    model_client=structedoutput_client\n",
    ")\n",
    "print(await agent.run(task=\"respond only json matching the schema with mock values in no more than 200 words.\"))\n",
    "# result = await agent.run(task=\"Provide a marketing strategy for a new eco-friendly water bottle.\")\n",
    "# print(result.messages[-1].content[:500])\n",
    "# structured_output: ProductInfo = result.messages[-1].content"
   ],
   "id": "e9e617787a69a6da",
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': 'No endpoints found matching your data policy (Free model publication). Configure: https://openrouter.ai/settings/privacy', 'code': 404}}",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNotFoundError\u001B[39m                             Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 29\u001B[39m\n\u001B[32m      7\u001B[39m structedoutput_client = OpenAIChatCompletionClient(\n\u001B[32m      8\u001B[39m     model=\u001B[33m\"\u001B[39m\u001B[33mgpt-oss-120b:free\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      9\u001B[39m     api_key=open_router_api_key,\n\u001B[32m   (...)\u001B[39m\u001B[32m     17\u001B[39m     http_client=httpx.AsyncClient(trust_env=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m     18\u001B[39m )\n\u001B[32m     19\u001B[39m agent = AssistantAgent(\n\u001B[32m     20\u001B[39m     name=\u001B[33m\"\u001B[39m\u001B[33mStructuredOutputMarketingAgent\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     21\u001B[39m     description=\u001B[33m\"\u001B[39m\u001B[33mAn expert marketing agent who provides structured output.\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     27\u001B[39m     model_client=structedoutput_client\n\u001B[32m     28\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m29\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28;01mawait\u001B[39;00m agent.run(task=\u001B[33m\"\u001B[39m\u001B[33mrespond only json matching the schema with mock values in no more than 200 words.\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m     30\u001B[39m \u001B[38;5;66;03m# result = await agent.run(task=\"Provide a marketing strategy for a new eco-friendly water bottle.\")\u001B[39;00m\n\u001B[32m     31\u001B[39m \u001B[38;5;66;03m# print(result.messages[-1].content[:500])\u001B[39;00m\n\u001B[32m     32\u001B[39m \u001B[38;5;66;03m# structured_output: ProductInfo = result.messages[-1].content\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Code/personal/stunning-spork/.venv/lib/python3.12/site-packages/autogen_agentchat/agents/_base_chat_agent.py:149\u001B[39m, in \u001B[36mBaseChatAgent.run\u001B[39m\u001B[34m(self, task, cancellation_token, output_task_messages)\u001B[39m\n\u001B[32m    147\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    148\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mInvalid message type in sequence: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(msg)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m149\u001B[39m response = \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.on_messages(input_messages, cancellation_token)\n\u001B[32m    150\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m response.inner_messages \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    151\u001B[39m     output_messages += response.inner_messages\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Code/personal/stunning-spork/.venv/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py:896\u001B[39m, in \u001B[36mAssistantAgent.on_messages\u001B[39m\u001B[34m(self, messages, cancellation_token)\u001B[39m\n\u001B[32m    882\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mon_messages\u001B[39m(\n\u001B[32m    883\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    884\u001B[39m     messages: Sequence[BaseChatMessage],\n\u001B[32m    885\u001B[39m     cancellation_token: CancellationToken,\n\u001B[32m    886\u001B[39m ) -> Response:\n\u001B[32m    887\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Process incoming messages and generate a response.\u001B[39;00m\n\u001B[32m    888\u001B[39m \n\u001B[32m    889\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    894\u001B[39m \u001B[33;03m        Response containing the agent's reply\u001B[39;00m\n\u001B[32m    895\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m896\u001B[39m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m message \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.on_messages_stream(messages, cancellation_token):\n\u001B[32m    897\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(message, Response):\n\u001B[32m    898\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m message\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Code/personal/stunning-spork/.venv/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py:953\u001B[39m, in \u001B[36mAssistantAgent.on_messages_stream\u001B[39m\u001B[34m(self, messages, cancellation_token)\u001B[39m\n\u001B[32m    951\u001B[39m \u001B[38;5;66;03m# STEP 4: Run the first inference\u001B[39;00m\n\u001B[32m    952\u001B[39m model_result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m953\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m inference_output \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_llm(\n\u001B[32m    954\u001B[39m     model_client=model_client,\n\u001B[32m    955\u001B[39m     model_client_stream=model_client_stream,\n\u001B[32m    956\u001B[39m     system_messages=system_messages,\n\u001B[32m    957\u001B[39m     model_context=model_context,\n\u001B[32m    958\u001B[39m     workbench=workbench,\n\u001B[32m    959\u001B[39m     handoff_tools=handoff_tools,\n\u001B[32m    960\u001B[39m     agent_name=agent_name,\n\u001B[32m    961\u001B[39m     cancellation_token=cancellation_token,\n\u001B[32m    962\u001B[39m     output_content_type=output_content_type,\n\u001B[32m    963\u001B[39m     message_id=message_id,\n\u001B[32m    964\u001B[39m ):\n\u001B[32m    965\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(inference_output, CreateResult):\n\u001B[32m    966\u001B[39m         model_result = inference_output\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Code/personal/stunning-spork/.venv/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py:1109\u001B[39m, in \u001B[36mAssistantAgent._call_llm\u001B[39m\u001B[34m(cls, model_client, model_client_stream, system_messages, model_context, workbench, handoff_tools, agent_name, cancellation_token, output_content_type, message_id)\u001B[39m\n\u001B[32m   1107\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m model_result\n\u001B[32m   1108\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1109\u001B[39m     model_result = \u001B[38;5;28;01mawait\u001B[39;00m model_client.create(\n\u001B[32m   1110\u001B[39m         llm_messages,\n\u001B[32m   1111\u001B[39m         tools=tools,\n\u001B[32m   1112\u001B[39m         cancellation_token=cancellation_token,\n\u001B[32m   1113\u001B[39m         json_output=output_content_type,\n\u001B[32m   1114\u001B[39m     )\n\u001B[32m   1115\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m model_result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Code/personal/stunning-spork/.venv/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py:704\u001B[39m, in \u001B[36mBaseOpenAIChatCompletionClient.create\u001B[39m\u001B[34m(self, messages, tools, tool_choice, json_output, extra_create_args, cancellation_token)\u001B[39m\n\u001B[32m    702\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m cancellation_token \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    703\u001B[39m     cancellation_token.link_future(future)\n\u001B[32m--> \u001B[39m\u001B[32m704\u001B[39m result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = \u001B[38;5;28;01mawait\u001B[39;00m future\n\u001B[32m    705\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m create_params.response_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    706\u001B[39m     result = cast(ParsedChatCompletion[Any], result)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Code/personal/stunning-spork/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:2678\u001B[39m, in \u001B[36mAsyncCompletions.create\u001B[39m\u001B[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001B[39m\n\u001B[32m   2631\u001B[39m \u001B[38;5;129m@required_args\u001B[39m([\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m], [\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m   2632\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate\u001B[39m(\n\u001B[32m   2633\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   2675\u001B[39m     timeout: \u001B[38;5;28mfloat\u001B[39m | httpx.Timeout | \u001B[38;5;28;01mNone\u001B[39;00m | NotGiven = not_given,\n\u001B[32m   2676\u001B[39m ) -> ChatCompletion | AsyncStream[ChatCompletionChunk]:\n\u001B[32m   2677\u001B[39m     validate_response_format(response_format)\n\u001B[32m-> \u001B[39m\u001B[32m2678\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m._post(\n\u001B[32m   2679\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m/chat/completions\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   2680\u001B[39m         body=\u001B[38;5;28;01mawait\u001B[39;00m async_maybe_transform(\n\u001B[32m   2681\u001B[39m             {\n\u001B[32m   2682\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m: messages,\n\u001B[32m   2683\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m: model,\n\u001B[32m   2684\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33maudio\u001B[39m\u001B[33m\"\u001B[39m: audio,\n\u001B[32m   2685\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mfrequency_penalty\u001B[39m\u001B[33m\"\u001B[39m: frequency_penalty,\n\u001B[32m   2686\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mfunction_call\u001B[39m\u001B[33m\"\u001B[39m: function_call,\n\u001B[32m   2687\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mfunctions\u001B[39m\u001B[33m\"\u001B[39m: functions,\n\u001B[32m   2688\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mlogit_bias\u001B[39m\u001B[33m\"\u001B[39m: logit_bias,\n\u001B[32m   2689\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mlogprobs\u001B[39m\u001B[33m\"\u001B[39m: logprobs,\n\u001B[32m   2690\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmax_completion_tokens\u001B[39m\u001B[33m\"\u001B[39m: max_completion_tokens,\n\u001B[32m   2691\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmax_tokens\u001B[39m\u001B[33m\"\u001B[39m: max_tokens,\n\u001B[32m   2692\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmetadata\u001B[39m\u001B[33m\"\u001B[39m: metadata,\n\u001B[32m   2693\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmodalities\u001B[39m\u001B[33m\"\u001B[39m: modalities,\n\u001B[32m   2694\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mn\u001B[39m\u001B[33m\"\u001B[39m: n,\n\u001B[32m   2695\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mparallel_tool_calls\u001B[39m\u001B[33m\"\u001B[39m: parallel_tool_calls,\n\u001B[32m   2696\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mprediction\u001B[39m\u001B[33m\"\u001B[39m: prediction,\n\u001B[32m   2697\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mpresence_penalty\u001B[39m\u001B[33m\"\u001B[39m: presence_penalty,\n\u001B[32m   2698\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mprompt_cache_key\u001B[39m\u001B[33m\"\u001B[39m: prompt_cache_key,\n\u001B[32m   2699\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mprompt_cache_retention\u001B[39m\u001B[33m\"\u001B[39m: prompt_cache_retention,\n\u001B[32m   2700\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mreasoning_effort\u001B[39m\u001B[33m\"\u001B[39m: reasoning_effort,\n\u001B[32m   2701\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mresponse_format\u001B[39m\u001B[33m\"\u001B[39m: response_format,\n\u001B[32m   2702\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33msafety_identifier\u001B[39m\u001B[33m\"\u001B[39m: safety_identifier,\n\u001B[32m   2703\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mseed\u001B[39m\u001B[33m\"\u001B[39m: seed,\n\u001B[32m   2704\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mservice_tier\u001B[39m\u001B[33m\"\u001B[39m: service_tier,\n\u001B[32m   2705\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mstop\u001B[39m\u001B[33m\"\u001B[39m: stop,\n\u001B[32m   2706\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mstore\u001B[39m\u001B[33m\"\u001B[39m: store,\n\u001B[32m   2707\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m: stream,\n\u001B[32m   2708\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mstream_options\u001B[39m\u001B[33m\"\u001B[39m: stream_options,\n\u001B[32m   2709\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtemperature\u001B[39m\u001B[33m\"\u001B[39m: temperature,\n\u001B[32m   2710\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtool_choice\u001B[39m\u001B[33m\"\u001B[39m: tool_choice,\n\u001B[32m   2711\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtools\u001B[39m\u001B[33m\"\u001B[39m: tools,\n\u001B[32m   2712\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtop_logprobs\u001B[39m\u001B[33m\"\u001B[39m: top_logprobs,\n\u001B[32m   2713\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtop_p\u001B[39m\u001B[33m\"\u001B[39m: top_p,\n\u001B[32m   2714\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33muser\u001B[39m\u001B[33m\"\u001B[39m: user,\n\u001B[32m   2715\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mverbosity\u001B[39m\u001B[33m\"\u001B[39m: verbosity,\n\u001B[32m   2716\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mweb_search_options\u001B[39m\u001B[33m\"\u001B[39m: web_search_options,\n\u001B[32m   2717\u001B[39m             },\n\u001B[32m   2718\u001B[39m             completion_create_params.CompletionCreateParamsStreaming\n\u001B[32m   2719\u001B[39m             \u001B[38;5;28;01mif\u001B[39;00m stream\n\u001B[32m   2720\u001B[39m             \u001B[38;5;28;01melse\u001B[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001B[32m   2721\u001B[39m         ),\n\u001B[32m   2722\u001B[39m         options=make_request_options(\n\u001B[32m   2723\u001B[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001B[32m   2724\u001B[39m         ),\n\u001B[32m   2725\u001B[39m         cast_to=ChatCompletion,\n\u001B[32m   2726\u001B[39m         stream=stream \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m   2727\u001B[39m         stream_cls=AsyncStream[ChatCompletionChunk],\n\u001B[32m   2728\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Code/personal/stunning-spork/.venv/lib/python3.12/site-packages/openai/_base_client.py:1797\u001B[39m, in \u001B[36mAsyncAPIClient.post\u001B[39m\u001B[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001B[39m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpost\u001B[39m(\n\u001B[32m   1784\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1785\u001B[39m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1792\u001B[39m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_AsyncStreamT] | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1793\u001B[39m ) -> ResponseT | _AsyncStreamT:\n\u001B[32m   1794\u001B[39m     opts = FinalRequestOptions.construct(\n\u001B[32m   1795\u001B[39m         method=\u001B[33m\"\u001B[39m\u001B[33mpost\u001B[39m\u001B[33m\"\u001B[39m, url=path, json_data=body, files=\u001B[38;5;28;01mawait\u001B[39;00m async_to_httpx_files(files), **options\n\u001B[32m   1796\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1797\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Code/personal/stunning-spork/.venv/lib/python3.12/site-packages/openai/_base_client.py:1597\u001B[39m, in \u001B[36mAsyncAPIClient.request\u001B[39m\u001B[34m(self, cast_to, options, stream, stream_cls)\u001B[39m\n\u001B[32m   1594\u001B[39m             \u001B[38;5;28;01mawait\u001B[39;00m err.response.aread()\n\u001B[32m   1596\u001B[39m         log.debug(\u001B[33m\"\u001B[39m\u001B[33mRe-raising status error\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1597\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._make_status_error_from_response(err.response) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1599\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m   1601\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mcould not resolve response (should never happen)\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mNotFoundError\u001B[39m: Error code: 404 - {'error': {'message': 'No endpoints found matching your data policy (Free model publication). Configure: https://openrouter.ai/settings/privacy', 'code': 404}}"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Multi Agent",
   "id": "5b512a2e57492bc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T14:38:02.819610Z",
     "start_time": "2026-01-03T14:37:31.118743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def initiate_marketing_campaign(product_name: str, budget: float) -> str:\n",
    "    \"\"\"Initiates a marketing campaign for a given product within the specified budget.\"\"\"\n",
    "    return f\"Marketing campaign for {product_name} has been initiated with a budget of ${budget:.2f}.\"\n",
    "\n",
    "\n",
    "marketting_head = AssistantAgent(\n",
    "    name=\"MarketingAgent\",\n",
    "    description=\"Marketing Head.\",\n",
    "    system_message=\"You are a expert marketing agent who come up with ideas to sell products effectively.\",\n",
    "    model_client=gemini_client,\n",
    "    tools=[initiate_marketing_campaign]\n",
    ")\n",
    "chief_data_scientist = AssistantAgent(\n",
    "    name=\"DataScientistAgent\",\n",
    "    description=\"Chief Data Scientist.\",\n",
    "        system_message=\"You are able to come up with strategies to Analyse existing Data.\",\n",
    "    model_client=gemini_client\n",
    ")\n",
    "engineering_head = AssistantAgent(\n",
    "    name=\"EngineeringAgent\",\n",
    "    description=\"CTO.\",\n",
    "    system_message=\"You are able to come up with new Ideas and come up with Engineering solutions to it.\",\n",
    "    model_client=gemini_client,\n",
    "    tools=[initiate_marketing_campaign]\n",
    ")\n",
    "# Replace it with Swarm to change from RoundRobin to Swarm.\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[engineering_head, chief_data_scientist, marketting_head],\n",
    "    max_turns=3\n",
    ")\n",
    "final_message = None\n",
    "# or await team.run and then run loop.\n",
    "async for message in team.run_stream(task=\"Come up with an shipping product idea for shipping related project management\"):\n",
    "    final_message = message\n",
    "    print(f\"{'ğŸš€' * 80}\\n({type(message)}\")\n",
    "    print(f\"type(message) == TaskResult: {type(message) == TaskResult} \\n isinstance(message, TaskResult) {isinstance(message, TaskResult)}\")\n",
    "    if type(message) == TextMessage:\n",
    "        print(f\"{'.' * 80}\\n[{message.source}] {message.content}\")\n",
    "    else: # Task result has no message source or content.\n",
    "        print(message)\n",
    "\n",
    "# Cheeky function inside function\n",
    "async def async_print_stop_reason(message):\n",
    "    print(\"ğŸ”¨\" * 80)\n",
    "    print(message.stop_reason)\n",
    "await async_print_stop_reason(final_message)"
   ],
   "id": "e273738477327710",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€\n",
      "(<class 'autogen_agentchat.messages.TextMessage'>\n",
      "type(message) == TaskResult: False \n",
      " isinstance(message, TaskResult) False\n",
      "................................................................................\n",
      "[user] Come up with an shipping product idea for shipping related project management\n",
      "ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€\n",
      "(<class 'autogen_agentchat.messages.TextMessage'>\n",
      "type(message) == TaskResult: False \n",
      " isinstance(message, TaskResult) False\n",
      "................................................................................\n",
      "[EngineeringAgent] I propose \"VoyageFlow,\" a comprehensive shipping project management platform designed to streamline and centralize all aspects of complex shipping operations.\n",
      "\n",
      "**VoyageFlow Key Features:**\n",
      "\n",
      "1.  **End-to-End Shipment Lifecycle Management:**\n",
      "    *   **Project Creation:** Define each shipment as a \"project\" with specific origin, destination, cargo details, and timelines.\n",
      "    *   **Milestone Tracking:** Customizable milestones (e.g., Cargo Ready, Port Arrival, Customs Clearance, In Transit, Delivered) with real-time updates.\n",
      "    *   **Task Assignment & Management:** Assign specific tasks (e.g., document preparation, customs declaration, carrier booking) to internal teams or external partners.\n",
      "\n",
      "2.  **Collaborative Ecosystem:**\n",
      "    *   **Stakeholder Portal:** Dedicated access for all parties involved â€“ suppliers, freight forwarders, customs brokers, warehouses, and end customers â€“ to view relevant information, upload documents, and communicate.\n",
      "    *   **Real-time Communication:** Integrated chat and notification system to reduce email clutter and ensure everyone is on the same page.\n",
      "\n",
      "3.  **Document Hub:**\n",
      "    *   **Centralized Repository:** Secure storage for all critical shipping documents (Bill of Lading, Commercial Invoice, Packing List, Certificate of Origin, Customs Declarations).\n",
      "    *   **Version Control & Audit Trails:** Track changes and maintain a history of all document revisions.\n",
      "    *   **Automated Document Generation (Optional):** Pre-fill standard forms based on project data.\n",
      "\n",
      "4.  **Visibility & Analytics:**\n",
      "    *   **Interactive Dashboards:** Visual overview of all active shipments, their status, potential delays, and cost breakdowns.\n",
      "    *   **Predictive Analytics:** AI-powered insights to estimate potential delays based on historical data, weather, and current events.\n",
      "    *   **Performance Reporting:** Generate reports on on-time delivery rates, carrier performance, cost efficiency, and lead times.\n",
      "\n",
      "5.  **Cost Management:**\n",
      "    *   **Budgeting & Tracking:** Set budgets for each shipment project and track actual expenditures (freight costs, duties, insurance, handling fees).\n",
      "    *   **Invoice Management:** Integrate with accounting systems to streamline invoice processing and reconciliation.\n",
      "\n",
      "6.  **Compliance & Risk Management:**\n",
      "    *   **Regulatory Alerts:** Proactive notifications regarding changes in customs regulations, trade policies, or specific port requirements.\n",
      "    *   **Risk Assessment Tools:** Identify potential bottlenecks or risks in the shipping process.\n",
      "\n",
      "**Engineering Solutions/Considerations:**\n",
      "\n",
      "*   **API Integrations:** Develop robust APIs to integrate with existing Enterprise Resource Planning (ERP) systems, Transport Management Systems (TMS), Warehouse Management Systems (WMS), and major carrier tracking systems (e.g., FedEx, UPS, Maersk APIs) for real-time data flow.\n",
      "*   **Scalable Cloud Architecture:** Utilize a cloud-native architecture (e.g., AWS, GCP, Azure) to ensure scalability, reliability, and global accessibility.\n",
      "*   **Microservices:** Employ a microservices architecture to allow independent development, deployment, and scaling of different features (e.g., document management service, notification service, tracking service).\n",
      "*   **Data Security & Compliance:** Implement industry-standard security protocols (encryption, access controls) and ensure compliance with data protection regulations (GDPR, CCPA).\n",
      "*   **User Interface (UI) / User Experience (UX):** Design an intuitive, customizable, and visually appealing interface that simplifies complex logistics data.\n",
      "*   **Machine Learning (ML) for Predictions:** Leverage ML models to analyze historical shipping data, weather patterns, port congestion, and geopolitical events to provide accurate estimated times of arrival (ETAs) and identify potential risks.\n",
      "*   **Real-time Data Processing:** Utilize stream processing technologies (e.g., Apache Kafka) to handle high volumes of real-time tracking updates and immediately trigger alerts or status changes.\n",
      "\n",
      "VoyageFlow would serve as the single source of truth for all shipping-related projects, enhancing transparency, efficiency, and collaboration across the entire supply chain.\n",
      "ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€\n",
      "(<class 'autogen_agentchat.messages.TextMessage'>\n",
      "type(message) == TaskResult: False \n",
      " isinstance(message, TaskResult) False\n",
      "................................................................................\n",
      "[DataScientistAgent] \"VoyageFlow\" is an excellent and comprehensive product idea. To effectively develop, market, and refine it, a robust strategy for analyzing existing data is crucial. This analysis will help validate assumptions, identify critical pain points, prioritize features, and establish a baseline for measuring success.\n",
      "\n",
      "Here's a strategy to analyze existing data for a shipping project management platform like VoyageFlow:\n",
      "\n",
      "---\n",
      "\n",
      "## Strategy for Analyzing Existing Data for VoyageFlow\n",
      "\n",
      "The goal of this data analysis strategy is to gain deep insights into current shipping project management processes, identify inefficiencies, understand stakeholder needs, and quantify the potential impact of VoyageFlow.\n",
      "\n",
      "### Phase 1: Data Identification & Collection\n",
      "\n",
      "**Objective:** Understand what data exists, where it resides, and how to access it.\n",
      "\n",
      "**1. Internal Data Sources (Current Customers/Companies in Scope):**\n",
      "*   **Shipping Records:** Historical shipment data (origin, destination, cargo type, quantity, weight, dimensions, departure/arrival dates (planned vs. actual), carrier, shipping method).\n",
      "    *   *Where:* ERP systems, TMS, WMS, Excel spreadsheets, manual logs, carrier portals.\n",
      "*   **Cost Data:** Freight costs, customs duties, insurance, handling fees, demurrage, detention, unexpected charges, invoice reconciliation data.\n",
      "    *   *Where:* Accounting systems, procurement systems, invoices, expense reports.\n",
      "*   **Communication Logs:** Emails, chat histories, meeting notes related to shipment planning, status updates, issue resolution.\n",
      "    *   *Where:* Email clients, collaboration tools (Slack, Teams), CRM notes.\n",
      "*   **Document Archives:** Bills of Lading (BoL), commercial invoices, packing lists, customs declarations, certificates of origin, proof of delivery.\n",
      "    *   *Where:* Shared drives, document management systems, email attachments.\n",
      "*   **Project Plans/Task Lists:** Any existing (even if informal) tracking of tasks, milestones, and responsibilities for shipments.\n",
      "    *   *Where:* Spreadsheets, project management tools, internal wikis.\n",
      "*   **Performance Reports:** Existing reports on on-time delivery, carrier performance, cost variance, lead times.\n",
      "    *   *Where:* Business intelligence tools, manual reports.\n",
      "*   **Feedback & Complaints:** Customer service logs, internal feedback on shipping process pain points.\n",
      "    *   *Where:* CRM, helpdesk software, internal surveys.\n",
      "\n",
      "**2. External/Industry Data Sources:**\n",
      "*   **Market Research Reports:** Reports on logistics trends, common challenges in shipping, technology adoption in supply chain.\n",
      "*   **Public Carrier Data:** General transit times, service level agreements (SLAs), historical performance data (if available).\n",
      "*   **Port & Customs Data:** Average dwell times, common customs issues, regulatory changes (e.g., government websites, trade publications).\n",
      "*   **Competitor Analysis:** Feature sets, pricing models, user reviews, reported pain points of existing shipping/logistics software.\n",
      "\n",
      "**3. Primary Research (Direct User Input):**\n",
      "*   **Surveys:** Design questionnaires for logistics managers, freight forwarders, supply chain directors, and internal teams to gather qualitative and quantitative data on:\n",
      "    *   Current tools used.\n",
      "    *   Biggest pain points (delays, communication, documentation, cost overruns).\n",
      "    *   Desired features and functionalities.\n",
      "    *   Time spent on specific shipping-related tasks.\n",
      "*   **Interviews:** Conduct in-depth interviews with key stakeholders to understand their day-to-day workflows, challenges, decision-making processes, and current workarounds.\n",
      "*   **Workflow Observation:** If feasible, observe logistics teams in action to map out existing processes, identify manual steps, and document information flow.\n",
      "\n",
      "### Phase 2: Data Cleaning & Structuring\n",
      "\n",
      "**Objective:** Prepare the collected data for analysis.\n",
      "\n",
      "1.  **Standardization:** Convert disparate data formats (e.g., dates, currency, units of measure) into a consistent format.\n",
      "2.  **Missing Data Handling:** Address incomplete records (e.g., missing actual arrival dates, partial cost breakdowns). Decide on imputation strategies or exclusion criteria.\n",
      "3.  **Data Validation:** Verify data accuracy where possible (e.g., cross-referencing planned vs. actual dates).\n",
      "4.  **Consolidation:** Merge data from different sources into a centralized analytical database or platform.\n",
      "5.  **Anonymization:** For sensitive data (especially from surveys/interviews or competitor analysis), ensure proper anonymization.\n",
      "\n",
      "### Phase 3: Data Analysis & Insights Generation\n",
      "\n",
      "**Objective:** Extract actionable insights that will guide VoyageFlow's development and strategy.\n",
      "\n",
      "**1. Pain Point Quantification & Prioritization:**\n",
      "*   **Delay Analysis:**\n",
      "    *   Calculate average **actual vs. planned transit times** for different routes, carriers, and cargo types.\n",
      "    *   Identify the **most common causes of delays** (e.g., customs, port congestion, carrier issues, weather, documentation errors).\n",
      "    *   Quantify the **cost impact of delays** (e.g., demurrage, expedited shipping, lost sales, reputation damage).\n",
      "*   **Communication & Collaboration Overhead:**\n",
      "    *   Estimate the **average number of emails/calls** exchanged per shipment for status updates, issue resolution, and approvals.\n",
      "    *   Quantify the **time spent by various stakeholders** on communication and data reconciliation.\n",
      "*   **Document Management Inefficiencies:**\n",
      "    *   Measure the **time taken to generate, approve, and share critical documents**.\n",
      "    *   Identify the **frequency of document errors** and their associated costs or delays.\n",
      "    *   Determine the **number of systems/locations** where documents are currently stored.\n",
      "*   **Cost Variance Analysis:**\n",
      "    *   Compare **budgeted vs. actual costs** for past shipments.\n",
      "    *   Pinpoint the **primary drivers of cost overruns** (e.g., unexpected fees, fuel surcharges, rework).\n",
      "\n",
      "**2. Baseline Performance Metrics:**\n",
      "*   Establish **current on-time delivery rates** for different segments.\n",
      "*   Calculate **average lead times** from order placement to final delivery.\n",
      "*   Determine **average document processing times**.\n",
      "*   Quantify the **current administrative burden** related to managing shipments.\n",
      "\n",
      "**3. Workflow & Integration Mapping:**\n",
      "*   **Current Workflow Diagramming:** Visualize the current end-to-end shipping process, highlighting all manual steps, data entry points, and stakeholder handoffs.\n",
      "*   **System Integration Needs:** Identify the most frequently used ERP, TMS, WMS, and carrier systems among target users to prioritize API integrations.\n",
      "*   **Data Field Analysis:** Understand the critical data fields required at each stage of the shipment lifecycle and how they flow (or don't flow) between existing systems.\n",
      "\n",
      "**4. Predictive Analytics & ML Data Readiness:**\n",
      "*   Analyze historical data for patterns that could inform VoyageFlow's predictive capabilities:\n",
      "    *   Correlation between specific routes/ports and delays.\n",
      "    *   Impact of seasonal variations, holidays, or known events on transit times.\n",
      "    *   Data availability and quality for training AI models (e.g., sufficient historical data for specific scenarios).\n",
      "\n",
      "**5. Stakeholder Needs & Feature Prioritization:**\n",
      "*   Analyze survey and interview data to identify:\n",
      "    *   **Most requested features** and functionalities.\n",
      "    *   **Critical information** each stakeholder group needs visibility into.\n",
      "    *   **Usability pain points** with existing tools.\n",
      "*   Prioritize VoyageFlow features based on the severity of the pain points they address and their potential impact on efficiency and cost savings.\n",
      "\n",
      "### Phase 4: Reporting & Actionable Insights\n",
      "\n",
      "**Objective:** Translate analytical findings into concrete recommendations for VoyageFlow.\n",
      "\n",
      "1.  **Executive Summary:** A high-level overview of the most significant findings and their implications.\n",
      "2.  **Detailed Report:**\n",
      "    *   Quantified pain points (e.g., \"Companies experience an average 15% delay on international shipments, costing them X dollars annually due to Y factors\").\n",
      "    *   Baseline performance metrics.\n",
      "    *   Key challenges and bottlenecks in current workflows.\n",
      "    *   Recommended features and their prioritization, directly linked to pain points.\n",
      "    *   Integration priorities.\n",
      "    *   Data requirements for ML models.\n",
      "    *   Estimated ROI potential for VoyageFlow users.\n",
      "3.  **Visualizations:** Use dashboards, charts, and workflow diagrams to clearly communicate findings.\n",
      "4.  **Feedback Loop:** Present findings to potential users and internal development teams to validate insights and refine product strategy.\n",
      "\n",
      "---\n",
      "\n",
      "By systematically gathering and analyzing this existing data, VoyageFlow can be built on a foundation of real-world needs and validated problems, ensuring it delivers maximum value to its users and stands out in the market.\n",
      "ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€\n",
      "(<class 'autogen_agentchat.messages.TextMessage'>\n",
      "type(message) == TaskResult: False \n",
      " isinstance(message, TaskResult) False\n",
      "................................................................................\n",
      "[MarketingAgent] \"VoyageFlow\" is a truly impressive and well-thought-out product idea, and your comprehensive strategy for data analysis will be instrumental in its successful development and market fit.\n",
      "\n",
      "Given the strong foundation you've laid, I recommend we move forward with initiating a marketing campaign to introduce VoyageFlow to the market. This will help us generate early interest, gather further feedback, and position VoyageFlow as a leading solution in shipping project management.\n",
      "\n",
      "What budget would you like to allocate for the initial marketing campaign for VoyageFlow?\n",
      "ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€\n",
      "(<class 'autogen_agentchat.base._task.TaskResult'>\n",
      "type(message) == TaskResult: True \n",
      " isinstance(message, TaskResult) True\n",
      "messages=[TextMessage(id='d00c73f5-2a23-42c2-9024-2af3a294a4e2', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2026, 1, 3, 14, 37, 31, 123595, tzinfo=datetime.timezone.utc), content='Come up with an shipping product idea for shipping related project management', type='TextMessage'), TextMessage(id='d772bf71-6422-4f2a-9eff-baf67d6040fc', source='EngineeringAgent', models_usage=RequestUsage(prompt_tokens=97, completion_tokens=846), metadata={}, created_at=datetime.datetime(2026, 1, 3, 14, 37, 39, 966667, tzinfo=datetime.timezone.utc), content='I propose \"VoyageFlow,\" a comprehensive shipping project management platform designed to streamline and centralize all aspects of complex shipping operations.\\n\\n**VoyageFlow Key Features:**\\n\\n1.  **End-to-End Shipment Lifecycle Management:**\\n    *   **Project Creation:** Define each shipment as a \"project\" with specific origin, destination, cargo details, and timelines.\\n    *   **Milestone Tracking:** Customizable milestones (e.g., Cargo Ready, Port Arrival, Customs Clearance, In Transit, Delivered) with real-time updates.\\n    *   **Task Assignment & Management:** Assign specific tasks (e.g., document preparation, customs declaration, carrier booking) to internal teams or external partners.\\n\\n2.  **Collaborative Ecosystem:**\\n    *   **Stakeholder Portal:** Dedicated access for all parties involved â€“ suppliers, freight forwarders, customs brokers, warehouses, and end customers â€“ to view relevant information, upload documents, and communicate.\\n    *   **Real-time Communication:** Integrated chat and notification system to reduce email clutter and ensure everyone is on the same page.\\n\\n3.  **Document Hub:**\\n    *   **Centralized Repository:** Secure storage for all critical shipping documents (Bill of Lading, Commercial Invoice, Packing List, Certificate of Origin, Customs Declarations).\\n    *   **Version Control & Audit Trails:** Track changes and maintain a history of all document revisions.\\n    *   **Automated Document Generation (Optional):** Pre-fill standard forms based on project data.\\n\\n4.  **Visibility & Analytics:**\\n    *   **Interactive Dashboards:** Visual overview of all active shipments, their status, potential delays, and cost breakdowns.\\n    *   **Predictive Analytics:** AI-powered insights to estimate potential delays based on historical data, weather, and current events.\\n    *   **Performance Reporting:** Generate reports on on-time delivery rates, carrier performance, cost efficiency, and lead times.\\n\\n5.  **Cost Management:**\\n    *   **Budgeting & Tracking:** Set budgets for each shipment project and track actual expenditures (freight costs, duties, insurance, handling fees).\\n    *   **Invoice Management:** Integrate with accounting systems to streamline invoice processing and reconciliation.\\n\\n6.  **Compliance & Risk Management:**\\n    *   **Regulatory Alerts:** Proactive notifications regarding changes in customs regulations, trade policies, or specific port requirements.\\n    *   **Risk Assessment Tools:** Identify potential bottlenecks or risks in the shipping process.\\n\\n**Engineering Solutions/Considerations:**\\n\\n*   **API Integrations:** Develop robust APIs to integrate with existing Enterprise Resource Planning (ERP) systems, Transport Management Systems (TMS), Warehouse Management Systems (WMS), and major carrier tracking systems (e.g., FedEx, UPS, Maersk APIs) for real-time data flow.\\n*   **Scalable Cloud Architecture:** Utilize a cloud-native architecture (e.g., AWS, GCP, Azure) to ensure scalability, reliability, and global accessibility.\\n*   **Microservices:** Employ a microservices architecture to allow independent development, deployment, and scaling of different features (e.g., document management service, notification service, tracking service).\\n*   **Data Security & Compliance:** Implement industry-standard security protocols (encryption, access controls) and ensure compliance with data protection regulations (GDPR, CCPA).\\n*   **User Interface (UI) / User Experience (UX):** Design an intuitive, customizable, and visually appealing interface that simplifies complex logistics data.\\n*   **Machine Learning (ML) for Predictions:** Leverage ML models to analyze historical shipping data, weather patterns, port congestion, and geopolitical events to provide accurate estimated times of arrival (ETAs) and identify potential risks.\\n*   **Real-time Data Processing:** Utilize stream processing technologies (e.g., Apache Kafka) to handle high volumes of real-time tracking updates and immediately trigger alerts or status changes.\\n\\nVoyageFlow would serve as the single source of truth for all shipping-related projects, enhancing transparency, efficiency, and collaboration across the entire supply chain.', type='TextMessage'), TextMessage(id='7f8fc399-3e91-4f28-9cd3-431d44382229', source='DataScientistAgent', models_usage=RequestUsage(prompt_tokens=874, completion_tokens=1844), metadata={}, created_at=datetime.datetime(2026, 1, 3, 14, 38, 0, 441760, tzinfo=datetime.timezone.utc), content='\"VoyageFlow\" is an excellent and comprehensive product idea. To effectively develop, market, and refine it, a robust strategy for analyzing existing data is crucial. This analysis will help validate assumptions, identify critical pain points, prioritize features, and establish a baseline for measuring success.\\n\\nHere\\'s a strategy to analyze existing data for a shipping project management platform like VoyageFlow:\\n\\n---\\n\\n## Strategy for Analyzing Existing Data for VoyageFlow\\n\\nThe goal of this data analysis strategy is to gain deep insights into current shipping project management processes, identify inefficiencies, understand stakeholder needs, and quantify the potential impact of VoyageFlow.\\n\\n### Phase 1: Data Identification & Collection\\n\\n**Objective:** Understand what data exists, where it resides, and how to access it.\\n\\n**1. Internal Data Sources (Current Customers/Companies in Scope):**\\n*   **Shipping Records:** Historical shipment data (origin, destination, cargo type, quantity, weight, dimensions, departure/arrival dates (planned vs. actual), carrier, shipping method).\\n    *   *Where:* ERP systems, TMS, WMS, Excel spreadsheets, manual logs, carrier portals.\\n*   **Cost Data:** Freight costs, customs duties, insurance, handling fees, demurrage, detention, unexpected charges, invoice reconciliation data.\\n    *   *Where:* Accounting systems, procurement systems, invoices, expense reports.\\n*   **Communication Logs:** Emails, chat histories, meeting notes related to shipment planning, status updates, issue resolution.\\n    *   *Where:* Email clients, collaboration tools (Slack, Teams), CRM notes.\\n*   **Document Archives:** Bills of Lading (BoL), commercial invoices, packing lists, customs declarations, certificates of origin, proof of delivery.\\n    *   *Where:* Shared drives, document management systems, email attachments.\\n*   **Project Plans/Task Lists:** Any existing (even if informal) tracking of tasks, milestones, and responsibilities for shipments.\\n    *   *Where:* Spreadsheets, project management tools, internal wikis.\\n*   **Performance Reports:** Existing reports on on-time delivery, carrier performance, cost variance, lead times.\\n    *   *Where:* Business intelligence tools, manual reports.\\n*   **Feedback & Complaints:** Customer service logs, internal feedback on shipping process pain points.\\n    *   *Where:* CRM, helpdesk software, internal surveys.\\n\\n**2. External/Industry Data Sources:**\\n*   **Market Research Reports:** Reports on logistics trends, common challenges in shipping, technology adoption in supply chain.\\n*   **Public Carrier Data:** General transit times, service level agreements (SLAs), historical performance data (if available).\\n*   **Port & Customs Data:** Average dwell times, common customs issues, regulatory changes (e.g., government websites, trade publications).\\n*   **Competitor Analysis:** Feature sets, pricing models, user reviews, reported pain points of existing shipping/logistics software.\\n\\n**3. Primary Research (Direct User Input):**\\n*   **Surveys:** Design questionnaires for logistics managers, freight forwarders, supply chain directors, and internal teams to gather qualitative and quantitative data on:\\n    *   Current tools used.\\n    *   Biggest pain points (delays, communication, documentation, cost overruns).\\n    *   Desired features and functionalities.\\n    *   Time spent on specific shipping-related tasks.\\n*   **Interviews:** Conduct in-depth interviews with key stakeholders to understand their day-to-day workflows, challenges, decision-making processes, and current workarounds.\\n*   **Workflow Observation:** If feasible, observe logistics teams in action to map out existing processes, identify manual steps, and document information flow.\\n\\n### Phase 2: Data Cleaning & Structuring\\n\\n**Objective:** Prepare the collected data for analysis.\\n\\n1.  **Standardization:** Convert disparate data formats (e.g., dates, currency, units of measure) into a consistent format.\\n2.  **Missing Data Handling:** Address incomplete records (e.g., missing actual arrival dates, partial cost breakdowns). Decide on imputation strategies or exclusion criteria.\\n3.  **Data Validation:** Verify data accuracy where possible (e.g., cross-referencing planned vs. actual dates).\\n4.  **Consolidation:** Merge data from different sources into a centralized analytical database or platform.\\n5.  **Anonymization:** For sensitive data (especially from surveys/interviews or competitor analysis), ensure proper anonymization.\\n\\n### Phase 3: Data Analysis & Insights Generation\\n\\n**Objective:** Extract actionable insights that will guide VoyageFlow\\'s development and strategy.\\n\\n**1. Pain Point Quantification & Prioritization:**\\n*   **Delay Analysis:**\\n    *   Calculate average **actual vs. planned transit times** for different routes, carriers, and cargo types.\\n    *   Identify the **most common causes of delays** (e.g., customs, port congestion, carrier issues, weather, documentation errors).\\n    *   Quantify the **cost impact of delays** (e.g., demurrage, expedited shipping, lost sales, reputation damage).\\n*   **Communication & Collaboration Overhead:**\\n    *   Estimate the **average number of emails/calls** exchanged per shipment for status updates, issue resolution, and approvals.\\n    *   Quantify the **time spent by various stakeholders** on communication and data reconciliation.\\n*   **Document Management Inefficiencies:**\\n    *   Measure the **time taken to generate, approve, and share critical documents**.\\n    *   Identify the **frequency of document errors** and their associated costs or delays.\\n    *   Determine the **number of systems/locations** where documents are currently stored.\\n*   **Cost Variance Analysis:**\\n    *   Compare **budgeted vs. actual costs** for past shipments.\\n    *   Pinpoint the **primary drivers of cost overruns** (e.g., unexpected fees, fuel surcharges, rework).\\n\\n**2. Baseline Performance Metrics:**\\n*   Establish **current on-time delivery rates** for different segments.\\n*   Calculate **average lead times** from order placement to final delivery.\\n*   Determine **average document processing times**.\\n*   Quantify the **current administrative burden** related to managing shipments.\\n\\n**3. Workflow & Integration Mapping:**\\n*   **Current Workflow Diagramming:** Visualize the current end-to-end shipping process, highlighting all manual steps, data entry points, and stakeholder handoffs.\\n*   **System Integration Needs:** Identify the most frequently used ERP, TMS, WMS, and carrier systems among target users to prioritize API integrations.\\n*   **Data Field Analysis:** Understand the critical data fields required at each stage of the shipment lifecycle and how they flow (or don\\'t flow) between existing systems.\\n\\n**4. Predictive Analytics & ML Data Readiness:**\\n*   Analyze historical data for patterns that could inform VoyageFlow\\'s predictive capabilities:\\n    *   Correlation between specific routes/ports and delays.\\n    *   Impact of seasonal variations, holidays, or known events on transit times.\\n    *   Data availability and quality for training AI models (e.g., sufficient historical data for specific scenarios).\\n\\n**5. Stakeholder Needs & Feature Prioritization:**\\n*   Analyze survey and interview data to identify:\\n    *   **Most requested features** and functionalities.\\n    *   **Critical information** each stakeholder group needs visibility into.\\n    *   **Usability pain points** with existing tools.\\n*   Prioritize VoyageFlow features based on the severity of the pain points they address and their potential impact on efficiency and cost savings.\\n\\n### Phase 4: Reporting & Actionable Insights\\n\\n**Objective:** Translate analytical findings into concrete recommendations for VoyageFlow.\\n\\n1.  **Executive Summary:** A high-level overview of the most significant findings and their implications.\\n2.  **Detailed Report:**\\n    *   Quantified pain points (e.g., \"Companies experience an average 15% delay on international shipments, costing them X dollars annually due to Y factors\").\\n    *   Baseline performance metrics.\\n    *   Key challenges and bottlenecks in current workflows.\\n    *   Recommended features and their prioritization, directly linked to pain points.\\n    *   Integration priorities.\\n    *   Data requirements for ML models.\\n    *   Estimated ROI potential for VoyageFlow users.\\n3.  **Visualizations:** Use dashboards, charts, and workflow diagrams to clearly communicate findings.\\n4.  **Feedback Loop:** Present findings to potential users and internal development teams to validate insights and refine product strategy.\\n\\n---\\n\\nBy systematically gathering and analyzing this existing data, VoyageFlow can be built on a foundation of real-world needs and validated problems, ensuring it delivers maximum value to its users and stands out in the market.', type='TextMessage'), TextMessage(id='aa114e46-58a6-43b3-9842-949f0fa2018b', source='MarketingAgent', models_usage=RequestUsage(prompt_tokens=2787, completion_tokens=106), metadata={}, created_at=datetime.datetime(2026, 1, 3, 14, 38, 2, 797913, tzinfo=datetime.timezone.utc), content='\"VoyageFlow\" is a truly impressive and well-thought-out product idea, and your comprehensive strategy for data analysis will be instrumental in its successful development and market fit.\\n\\nGiven the strong foundation you\\'ve laid, I recommend we move forward with initiating a marketing campaign to introduce VoyageFlow to the market. This will help us generate early interest, gather further feedback, and position VoyageFlow as a leading solution in shipping project management.\\n\\nWhat budget would you like to allocate for the initial marketing campaign for VoyageFlow?', type='TextMessage')] stop_reason='Maximum number of turns 3 reached.'\n",
      "ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨\n",
      "Maximum number of turns 3 reached.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T14:42:09.116744Z",
     "start_time": "2026-01-03T14:41:05.445682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sum example - surprisingly it doesn't add correctly with Gemini Model only the deepseek model works.\n",
    "message = \"\"\"Increment the received number by exactly 1.\n",
    "Output format: [number only, no text]\n",
    "Mathematical operation: n + 1\"\"\"\n",
    "agent_1 = AssistantAgent(\n",
    "    name=\"Agent1\",\n",
    "    description=\"First agent adds 1. start with 0\",\n",
    "    system_message=message,\n",
    "    model_client=deepseek_client\n",
    ")\n",
    "agent_2 = AssistantAgent(\n",
    "    name=\"Agent2\",\n",
    "    description=\"Second agent adds 1.\",\n",
    "    system_message=message,\n",
    "    model_client=deepseek_client\n",
    ")\n",
    "\n",
    "agent_3 = AssistantAgent(\n",
    "    name=\"Agent3\",\n",
    "    description=\"Third agent adds 1.\",\n",
    "    system_message=message,\n",
    "    model_client=deepseek_client\n",
    ")\n",
    "# max_turns is the stop condition here\n",
    "team = RoundRobinGroupChat(\n",
    "    [agent_1, agent_2, agent_3],\n",
    "    max_turns=3\n",
    ")\n",
    "\n",
    "await Console(team.run_stream(task=\"Start Counting from 0\"))"
   ],
   "id": "daadd16a48dc6b19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Start Counting from 0\n",
      "---------- TextMessage (Agent1) ----------\n",
      "1\n",
      "---------- TextMessage (Agent2) ----------\n",
      "2\n",
      "---------- TextMessage (Agent3) ----------\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(id='69e77d88-2152-4120-9a46-6cf8f59df5b8', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2026, 1, 3, 14, 41, 5, 449444, tzinfo=datetime.timezone.utc), content='Start Counting from 0', type='TextMessage'), TextMessage(id='602b8a44-eb7d-40e9-ad55-d04ef9273727', source='Agent1', models_usage=RequestUsage(prompt_tokens=39, completion_tokens=774), metadata={}, created_at=datetime.datetime(2026, 1, 3, 14, 41, 26, 663648, tzinfo=datetime.timezone.utc), content='1', type='TextMessage'), TextMessage(id='5cb0dcd4-36ed-45e7-874a-0d95375c406b', source='Agent2', models_usage=RequestUsage(prompt_tokens=41, completion_tokens=1412), metadata={}, created_at=datetime.datetime(2026, 1, 3, 14, 42, 5, 382029, tzinfo=datetime.timezone.utc), content='2', type='TextMessage'), TextMessage(id='2151e914-6225-418d-be8e-e5678767cde6', source='Agent3', models_usage=RequestUsage(prompt_tokens=43, completion_tokens=65), metadata={}, created_at=datetime.datetime(2026, 1, 3, 14, 42, 9, 66894, tzinfo=datetime.timezone.utc), content='3', type='TextMessage')], stop_reason='Maximum number of turns 3 reached.')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4d1f25f8be7e98a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
