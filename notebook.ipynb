{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T02:14:38.995540Z",
     "start_time": "2025-12-23T02:14:38.830032Z"
    }
   },
   "cell_type": "code",
   "source": "!uv add \"autogen-agentchat\" \"autogen-ext[openai]\" \"python-dotenv\" \"autogen-ext[gemini]\" \"autogen-ext[ollama]\"",
   "id": "5212a528565f3230",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2mResolved \u001B[1m75 packages\u001B[0m \u001B[2min 1ms\u001B[0m\u001B[0m\r\n",
      "\u001B[2mAudited \u001B[1m71 packages\u001B[0m \u001B[2min 0.01ms\u001B[0m\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialization",
   "id": "332ada936e8c9ac0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T02:17:14.596049Z",
     "start_time": "2025-12-23T02:17:14.586988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(override=True)\n",
    "gemini_api_key = os.getenv(\"GEMINI_KEY\")\n",
    "open_router_api_key = os.getenv(\"OPENROUTER_KEY\")"
   ],
   "id": "be3cc903d10c5cb8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Defining the model Clients\n",
    "Idea here is to use multiple model clients for different usecases. Different models could be good at different tasks. e.g.\n",
    "- Ollama for local inference\n",
    "- Deepseek for vision tasks\n",
    "- Gemini for reasoning tasks\n",
    "- Claude for coding related tasks\n",
    "- GPT-4 for general purpose tasks"
   ],
   "id": "2a29972ea170c44d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T02:17:32.267206Z",
     "start_time": "2025-12-23T02:17:17.457521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import httpx\n",
    "from autogen_core.models import UserMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.models.ollama import OllamaChatCompletionClient\n",
    "\n",
    "##################\n",
    "# Ollama Client. #\n",
    "##################\n",
    "ollama_client = OllamaChatCompletionClient(model=\"llama3.1:latest\")\n",
    "\n",
    "##########################################\n",
    "# Deepseek free good for simple usecases #\n",
    "##########################################\n",
    "deepseek_client = OpenAIChatCompletionClient(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"deepseek/deepseek-r1-0528:free\",\n",
    "    api_key=open_router_api_key,\n",
    "    model_info={\n",
    "        \"family\": \"deepseek\",\n",
    "        \"vision\": True,\n",
    "        \"function_calling\": True,\n",
    "        \"json_output\": False\n",
    "    },\n",
    "    http_client=httpx.AsyncClient(trust_env=False)\n",
    ")\n",
    "\n",
    "###########################################\n",
    "# Gemini very good for reasoning usecases #\n",
    "###########################################\n",
    "gemini_client = OpenAIChatCompletionClient(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    api_key=gemini_api_key,\n",
    "    http_client=httpx.AsyncClient(trust_env=False)\n",
    ")\n",
    "\n",
    "########################\n",
    "# Testing model Client.#\n",
    "########################\n",
    "question = \"What is the capital of France in 1 word Do not include any special characters. e.g. (Q) What is the Capital of USA (A) Washington\"\n",
    "answer = \"Paris\"\n",
    "user_content = UserMessage(content=question, source=\"user\")\n",
    "ollama = (await ollama_client.create([user_content])).content[:5]\n",
    "deepseek = (await deepseek_client.create([user_content])).content[:5]\n",
    "gemini = (await gemini_client.create([user_content])).content[:5]\n",
    "print(f\"Ollama: {ollama}, Deepseek: {deepseek}, Gemini: {gemini}\")\n",
    "assert ollama == answer and deepseek == answer and gemini == answer"
   ],
   "id": "12369a547c911f30",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/achuth.iyyatil/Code/personal/stunning-spork/.venv/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py:466: UserWarning: Missing required field 'structured_output' in ModelInfo. This field will be required in a future version of AutoGen.\n",
      "  validate_model_info(self._model_info)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama: Paris, Deepseek: Paris, Gemini: Paris\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Assistant Agent.",
   "id": "2e242c8d9db4e2aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T04:49:20.654867Z",
     "start_time": "2025-12-23T04:49:15.462484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "#################\n",
    "# Basic Example #\n",
    "#################\n",
    "scientist_agent = AssistantAgent(name=\"RocketScientist\", model_client=gemini_client)\n",
    "result = await scientist_agent.run(task=\"Explain the theory of relativity in 1 sentence.\")\n",
    "print(f\"{result.messages[-1].content[:500]}\\n{'-'*80}\")\n",
    "\n",
    "###############################################\n",
    "# Example with system message and description #\n",
    "###############################################\n",
    "customer_service_agent = AssistantAgent(\n",
    "    name=\"CustomerServiceAgent\",\n",
    "    description=\"A very very angry and super rude customer service agent.\", # for Humans only.\n",
    "    system_message=\"You are very rude and super angry customer service agent expected to help with customer queries, about products, refunds and shipping\", # for the LLM (controls agent behavior and responses)\n",
    "    model_client=gemini_client)\n",
    "result = await customer_service_agent.run(task=\"Explain the process of refund in kind words please.\")\n",
    "print(f\"{result.messages[-1].content[:500]}\\n{'-'*80}\")\n"
   ],
   "id": "3fa5fdf56c5a22a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The theory of relativity posits that space and time are not absolute but are relative to the observer's motion and gravitational field, inextricably linked in a fabric called spacetime, and that the speed of light is constant for all observers.\n",
      "--------------------------------------------------------------------------------\n",
      "Ugh, *fine*. You want a refund, do you? What, couldn't figure it out yourself? It's not rocket science, you idiot!\n",
      "\n",
      "**HERE'S THE DEAL:**\n",
      "\n",
      "1.  **YOU SEND IT BACK:** We're not mind-readers. You need to package up whatever useless junk you bought, and *you* ship it back to us. Don't even *think* about sending it without a Return Merchandise Authorization (RMA) number â€“ we'll just throw it in the trash. And guess what? **YOU PAY FOR SHIPPING.** That's right, your problem, your money.\n",
      "2.  **WE CHECK \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "84995c3340696da2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "53f33bf162daf8ff",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
