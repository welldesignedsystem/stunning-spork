{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T05:01:00.793042Z",
     "start_time": "2026-01-09T05:01:00.367595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# imports\n",
    "import os\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import dotenv\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from pathlib import Path\n",
    "\n",
    "import httpx\n",
    "import asyncio\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from pydantic import BaseModel, Field\n",
    "from autogen_agentchat.base import TaskResult\n",
    "from autogen_core.tools import FunctionTool\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat, Swarm, SelectorGroupChat\n",
    "from autogen_core.models import UserMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.models.ollama import OllamaChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent, CodeExecutorAgent\n",
    "from autogen_core import Image as AGImage, CancellationToken  # We will use Image later\n",
    "from autogen_agentchat.messages import TextMessage, MultiModalMessage, CodeExecutionEvent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination, ExternalTermination\n",
    "from autogen_ext.code_executors.docker import DockerCommandLineCodeExecutor"
   ],
   "id": "3d119924c6d610cd",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Initialize",
   "id": "fafc2a0c45b82a02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T05:01:42.125120Z",
     "start_time": "2026-01-09T05:01:41.583637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.environ.pop('HTTP_PROXY', None)\n",
    "os.environ.pop('HTTPS_PROXY', None)\n",
    "os.environ.pop('http_proxy', None)\n",
    "os.environ.pop('https_proxy', None)\n",
    "\n",
    "dotenv.load_dotenv(override=True)\n",
    "gemini_api_key = os.getenv(\"GEMINI_KEY\")\n",
    "open_router_api_key = os.getenv(\"OPENROUTER_KEY\")\n",
    "\n",
    "# Or set to empty\n",
    "os.environ['HTTP_PROXY'] = ''\n",
    "os.environ['HTTPS_PROXY'] = ''\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/gemini-embedding-001\",\n",
    "    google_api_key = gemini_api_key,\n",
    ")\n",
    "print(embeddings.embed_query(\"testing!\")[:5])"
   ],
   "id": "c2a1b02b00edb645",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.036367375, -0.019505447, 0.016166167, -0.057357196, -0.008019263]\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T05:02:02.710983Z",
     "start_time": "2026-01-09T05:01:43.819371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##################\n",
    "# Ollama Client. #\n",
    "##################\n",
    "ollama_client = OllamaChatCompletionClient(model=\"llama3.1:latest\")\n",
    "\n",
    "##########################################\n",
    "# Deepseek free good for simple usecases #\n",
    "##########################################\n",
    "deepseek_client = OpenAIChatCompletionClient(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"deepseek/deepseek-r1-0528:free\",\n",
    "    api_key=open_router_api_key,\n",
    "    model_info={\n",
    "        \"family\": \"deepseek\",\n",
    "        \"structured_output\": False,\n",
    "        \"vision\": True,\n",
    "        \"function_calling\": True,\n",
    "        \"json_output\": False\n",
    "    },\n",
    "    http_client=httpx.AsyncClient(trust_env=False)\n",
    ")\n",
    "\n",
    "###########################################\n",
    "# Gemini very good for reasoning usecases #\n",
    "###########################################\n",
    "gemini_client = OpenAIChatCompletionClient(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    api_key=gemini_api_key,\n",
    "    http_client=httpx.AsyncClient(trust_env=False)\n",
    ")\n",
    "\n",
    "########################\n",
    "# Testing model Client.#\n",
    "########################\n",
    "question = \"What is the capital of France in 1 word Do not include any special characters. e.g. (Q) What is the Capital of USA (A) Washington\"\n",
    "answer = \"Paris\"\n",
    "user_content = UserMessage(content=question, source=\"user\")\n",
    "ollama = (await ollama_client.create([user_content])).content[:5]\n",
    "deepseek = (await deepseek_client.create([user_content])).content[:5]\n",
    "gemini = (await gemini_client.create([user_content])).content[:5]\n",
    "print(f\"Ollama: {ollama}, Deepseek: {deepseek}, Gemini: {gemini}\")\n",
    "assert ollama == answer and deepseek == answer and gemini == answer"
   ],
   "id": "af1f04121849f9a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama: Paris, Deepseek: Paris, Gemini: Paris\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Ingest to file",
   "id": "d4cbbd0b34ef378d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T04:56:59.202022Z",
     "start_time": "2026-01-09T04:55:32.662699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PDF_PATH=\"../project/A2013-18.pdf\"\n",
    "# 0. Verify PDF path\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "for file in os.listdir():\n",
    "    print(f\"  {file}\")\n",
    "if not os.path.exists(PDF_PATH):\n",
    "    raise FileNotFoundError(f\"PDF file not found: {PDF_PATH}\")\n",
    "\n",
    "# 1. Load PDF\n",
    "print(\"Loading PDF...\")\n",
    "loader = PyPDFLoader(PDF_PATH)\n",
    "documents = loader.load()\n",
    "print(f\"Loaded {len(documents)} pages\")\n",
    "\n",
    "# 2. Split into chunks\n",
    "print(\"Splitting documents...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Created {len(chunks)} chunks\")\n",
    "\n",
    "# 3. Create embeddings\n",
    "print(\"Creating embeddings...\")\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/gemini-embedding-001\"\n",
    ")\n",
    "\n",
    "# 4. Create and save FAISS vector store\n",
    "print(\"Building FAISS index...\")\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# Save to disk as files\n",
    "vectorstore.save_local(\"faiss_index\")\n",
    "print(\"✓ Vector store saved to 'faiss_index' folder\")\n",
    "\n",
    "# Later: Load from disk\n",
    "print(\"\\nLoading vector store from disk...\")\n",
    "loaded_vectorstore = FAISS.load_local(\n",
    "    \"faiss_index\",\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True  # Required for pickle files\n",
    ")\n",
    "\n",
    "# Test query\n",
    "query = \"What is this document about?\"\n",
    "results = loaded_vectorstore.similarity_search(query, k=3)\n",
    "print(f\"\\nQuery: {query}\")\n",
    "print(f\"Top result:\\n{results[0].page_content[:200]}\")"
   ],
   "id": "cca22d870fa2fb32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/achuth.iyyatil/Code/personal/stunning-spork/notes\n",
      "  Autogen Studio.pdf\n",
      "  Source.zip\n",
      "  Source\n",
      "  Autogen Roadmap.excalidraw\n",
      "  README.md\n",
      "  Autogen Module 4.pdf\n",
      "  Autogen .pdf\n",
      "Loading PDF...\n",
      "Loaded 370 pages\n",
      "Splitting documents...\n",
      "Created 1681 chunks\n",
      "Creating embeddings...\n",
      "Building FAISS index...\n",
      "✓ Vector store saved to 'faiss_index' folder\n",
      "\n",
      "Loading vector store from disk...\n",
      "\n",
      "Query: What is this document about?\n",
      "Top result:\n",
      "Names, addresses, descriptions \n",
      "and occupations of subscribers \n",
      "Witnesses (along with names, addresses, \n",
      "descriptions and occupations) \n",
      "A.B. of………….Merchant Signed before me \n",
      "Signature……………. \n",
      "C.D. of…\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T08:25:24.412534Z",
     "start_time": "2026-01-09T08:25:17.172809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "async def fetch_law_points(query: str, k:int = 5) -> str:\n",
    "    agent = AssistantAgent(\n",
    "        name='summarizer_agent',\n",
    "        model_client=gemini_client,\n",
    "        system_message=\"\"\"\n",
    "        You are a summarization agent. Summarize the given text concisely.\n",
    "        \"\"\",\n",
    "    )\n",
    "    results = loaded_vectorstore.similarity_search(query, k=k)\n",
    "    combined_text = \"\\n\\n\".join([doc.page_content for doc in results])\n",
    "    result = await agent.run(task=f\"\"\"\n",
    "        Summarize the contents below based on the context provided.\n",
    "        Context:\n",
    "        {combined_text}\n",
    "    \"\"\")\n",
    "    return result.messages[-1].content\n",
    "await fetch_law_points(\"What is this document about?\")"
   ],
   "id": "e31e5bd3d6bbb02d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The provided text outlines templates and requirements for company formation documents, specifically focusing on subscriber and witness details for a Memorandum of Association.\\n\\nIt details the necessary information for **subscribers** (names, addresses, descriptions, occupations, signatures, and number of shares taken) and **witnesses** (names, addresses, descriptions, occupations, and signatures).\\n\\nSpecial provisions are included for **One Person Companies (OPC)**, requiring a declaration from the sole subscriber to form the company and take all shares, and the appointment of a nominee in the event of the sole member's death.\\n\\nThe text also presents excerpts from the **Memorandum of Association for Unlimited Companies** (both with and without share capital), outlining sections for the company's name, registered office, and objects.\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Read from file based on query get the best n number of chunks and summarize it",
   "id": "e31172f656813903"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tools section",
   "id": "6e809f27354daeb3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Agents",
   "id": "30335564cdc60c28"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "361926df526f4da4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
